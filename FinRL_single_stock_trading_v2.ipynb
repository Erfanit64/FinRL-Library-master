{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idd1jem0TnST"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Single Stock Trading\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade single stock in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
    "\n",
    "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
    "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-single-stock-trading-37d6d7c30aac\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vglc_9N5-KZ"
   },
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex2ord116AbP"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1eLhMW36cLi"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eimeRv06YoK"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: single stock trading for AAPL\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n",
    "\n",
    "We use Apple Inc. stock: AAPL as an example throughout this article, because it is one of the most popular and profitable stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD3f90UnTnSU"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBUcBKap-oII"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40axJBAP5mer",
    "outputId": "82fdfeec-5b2e-4553-d95c-6c8d03ea1709"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to c:\\users\\e0690420\\appdata\\local\\temp\\pip-req-build-529m07xy\n",
      "Requirement already satisfied: numpy in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (1.19.2)\n",
      "Collecting pandas>=1.1.5\n",
      "  Downloading pandas-1.2.1-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "Collecting stockstats\n",
      "  Using cached stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Using cached yfinance-0.1.55.tar.gz (23 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (3.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (0.23.2)\n",
      "Collecting gym>=0.17\n",
      "  Downloading gym-0.18.0.tar.gz (1.6 MB)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Using cached stable_baselines3-0.10.0-py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: pytest in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (0.0.0)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (50.3.1.post20201107)\n",
      "Requirement already satisfied: wheel>=0.33.6 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from finrl==0.0.3) (0.35.1)\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to c:\\users\\e0690420\\appdata\\local\\temp\\pip-install-oyepb8k_\\pyfolio\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->finrl==0.0.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->finrl==0.0.3) (2020.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Using cached int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from yfinance->finrl==0.0.3) (2.24.0)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Using cached multitasking-0.0.9.tar.gz (8.1 kB)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from yfinance->finrl==0.0.3) (4.6.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from matplotlib->finrl==0.0.3) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from matplotlib->finrl==0.0.3) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from matplotlib->finrl==0.0.3) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from matplotlib->finrl==0.0.3) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from matplotlib->finrl==0.0.3) (2020.6.20)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (2.1.0)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from gym>=0.17->finrl==0.0.3) (1.6.0)\n",
      "Collecting torch>=1.4.0\n",
      "  Downloading torch-1.7.1-cp38-cp38-win_amd64.whl (184.0 MB)\n",
      "Collecting tensorboard; extra == \"extra\"\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting opencv-python; extra == \"extra\"\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Collecting atari-py~=0.2.0; extra == \"extra\"\n",
      "  Downloading atari-py-0.2.6.tar.gz (790 kB)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]->finrl==0.0.3) (5.7.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (20.3.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (20.4)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (1.9.0)\n",
      "Requirement already satisfied: toml in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (0.10.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pytest->finrl==0.0.3) (0.4.4)\n",
      "Requirement already satisfied: ipython>=3.2.3 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (7.19.0)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.11.0)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Using cached empyrical-0.5.5.tar.gz (52 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->finrl==0.0.3) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance->finrl==0.0.3) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance->finrl==0.0.3) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance->finrl==0.0.3) (2.10)\n",
      "Requirement already satisfied: future in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.0.3) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from torch>=1.4.0->stable-baselines3[extra]->finrl==0.0.3) (3.7.4.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.35.0-cp38-cp38-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.14.0-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: pygments in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (2.7.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (3.0.8)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.17.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (5.0.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.2.0)\n",
      "Collecting pandas-datareader>=0.2\n",
      "  Using cached pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\e0690420\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.2.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: finrl, yfinance, gym, pyfolio, multitasking, atari-py, empyrical\n",
      "  Building wheel for finrl (setup.py): started\n",
      "  Building wheel for finrl (setup.py): finished with status 'done'\n",
      "  Created wheel for finrl: filename=finrl-0.0.3-py3-none-any.whl size=28505 sha256=a1f0921af68f03b82a1dfc77cf35bbc412906027b8a9088353e1f273811bdfef\n",
      "  Stored in directory: C:\\Users\\e0690420\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ycg13jjv\\wheels\\e8\\19\\74\\11261997d6bdca44ba73e8eeedb94a3e3d340259516a0887eb\n",
      "  Building wheel for yfinance (setup.py): started\n",
      "  Building wheel for yfinance (setup.py): finished with status 'done'\n",
      "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22622 sha256=d7e57a3b66f5161955a9fb6196b7a1331ccffa10e390e560859dce1bf916545a\n",
      "  Stored in directory: c:\\users\\e0690420\\appdata\\local\\pip\\cache\\wheels\\b4\\c3\\39\\9c01ae2b4726f37024bba5592bec868b47a2fab5a786e8979a\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.18.0-py3-none-any.whl size=1656454 sha256=7227e6265047163058de2791052f49253fe4489901aa38b9bd822c3e9004c5d8\n",
      "  Stored in directory: c:\\users\\e0690420\\appdata\\local\\pip\\cache\\wheels\\d8\\e7\\68\\a3f0f1b5831c9321d7523f6fd4e0d3f83f2705a1cbd5daaa79\n",
      "  Building wheel for pyfolio (setup.py): started\n",
      "  Building wheel for pyfolio (setup.py): finished with status 'done'\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=76264 sha256=c3ffd084f6306a11b61d4260f3c325df1c974365219f74fabb43b3c4c35cec28\n",
      "  Stored in directory: C:\\Users\\e0690420\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ycg13jjv\\wheels\\7b\\59\\8b\\3c276a18b58c04a1fd0e1351e979fb5396f93fbde5b5438df1\n",
      "  Building wheel for multitasking (setup.py): started\n",
      "  Building wheel for multitasking (setup.py): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.9-py3-none-any.whl size=8372 sha256=acb9d0f32df873cceb6c083fd9b24b2ee5a89810d119d0eba4c612059226a20d\n",
      "  Stored in directory: c:\\users\\e0690420\\appdata\\local\\pip\\cache\\wheels\\57\\6d\\a3\\a39b839cc75274d2acfb1c58bfead2f726c6577fe8c4723f13\n",
      "  Building wheel for atari-py (setup.py): started\n",
      "  Building wheel for atari-py (setup.py): finished with status 'done'\n",
      "  Created wheel for atari-py: filename=atari_py-0.2.6-cp38-cp38-win_amd64.whl size=1155041 sha256=fa067101ff8f6fba4d3385b088f2164e03cdf987e715a82ca1f16c02baea22cb\n",
      "  Stored in directory: c:\\users\\e0690420\\appdata\\local\\pip\\cache\\wheels\\7f\\5e\\27\\2e90b9887063d82ee2f9f8b2f8db76bb2290aa281dc40449c8\n",
      "  Building wheel for empyrical (setup.py): started\n",
      "  Building wheel for empyrical (setup.py): finished with status 'done'\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39778 sha256=13498c1bb7a1f7b632c733f0802d7d2c800bdfe51333d62e715a2d040e0f0979\n",
      "  Stored in directory: c:\\users\\e0690420\\appdata\\local\\pip\\cache\\wheels\\0d\\68\\bb\\926065fb744e7d7cb67334cb1a9c696722abc8303e5dc9a8d0\n",
      "Successfully built finrl yfinance gym pyfolio multitasking atari-py empyrical\n",
      "Installing collected packages: pandas, int-date, stockstats, multitasking, yfinance, pyglet, gym, torch, tensorboard-plugin-wit, oauthlib, requests-oauthlib, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, google-auth-oauthlib, grpcio, markdown, absl-py, protobuf, tensorboard, opencv-python, atari-py, stable-baselines3, pandas-datareader, empyrical, pyfolio, finrl\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\e0690420\\\\Anaconda3\\\\Lib\\\\site-packages\\\\~andas\\\\_libs\\\\algos.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXyHD6ir5sxk"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG17M4JwTnSZ"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-0bsNMMTnSZ",
    "outputId": "cb2a75db-9260-4637-e3e3-77b5511fc078"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from finrl.trade.backtest import BackTestStats, BaselineStats, BackTestPlot\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uIPbzYs1TnSd"
   },
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos2IZAL54pp"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zp6lL6dZ53rX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBPM0sVvTnSg"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCGVmtGzjORf"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FBEiH5gOgMOx",
    "outputId": "07f55868-6c04-45c0-a43a-5c980532e284"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2000-01-01'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sWLMNQ8CgMRx",
    "outputId": "0b61d201-7eb3-4888-cc3c-37dcceb218da"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2021-01-01'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# from config.py end_date is a string\n",
    "config.END_DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmFpuBEZhkF3"
   },
   "source": [
    "ticker_list is a list of stock tickers, in a single stock trading case, the list contains only 1 ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIFikNyTnSg",
    "outputId": "faf30b8f-f6ba-4449-ac14-44843f639765"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3022, 8)\n"
     ]
    }
   ],
   "source": [
    "# Download and save the data in a pandas DataFrame:\n",
    "data_df = YahooDownloader(start_date = '2009-01-01',\n",
    "                          end_date = '2021-01-01',\n",
    "                          ticker_list = ['AAPL']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8ZKQmw6TnSl",
    "outputId": "021648bb-20aa-4c63-f215-2ae76ceb068f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3022, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "Vi6D_ED6TnSs",
    "outputId": "9b66e8f3-ecbf-44b6-9d26-141b6340e27a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date      open      high       low     close      volume   tic  day\n",
       "0  2008-12-31  3.070357  3.133571  3.047857  2.629544   607541200  AAPL    2\n",
       "1  2009-01-02  3.067143  3.251429  3.041429  2.795913   746015200  AAPL    4\n",
       "2  2009-01-05  3.327500  3.435000  3.311071  2.913912  1181608400  AAPL    0\n",
       "3  2009-01-06  3.426786  3.470357  3.299643  2.865849  1289310400  AAPL    1\n",
       "4  2009-01-07  3.278929  3.303571  3.223572  2.803923   753048800  AAPL    2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-31</td>\n      <td>3.070357</td>\n      <td>3.133571</td>\n      <td>3.047857</td>\n      <td>2.629544</td>\n      <td>607541200</td>\n      <td>AAPL</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>3.067143</td>\n      <td>3.251429</td>\n      <td>3.041429</td>\n      <td>2.795913</td>\n      <td>746015200</td>\n      <td>AAPL</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-05</td>\n      <td>3.327500</td>\n      <td>3.435000</td>\n      <td>3.311071</td>\n      <td>2.913912</td>\n      <td>1181608400</td>\n      <td>AAPL</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-06</td>\n      <td>3.426786</td>\n      <td>3.470357</td>\n      <td>3.299643</td>\n      <td>2.865849</td>\n      <td>1289310400</td>\n      <td>AAPL</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-07</td>\n      <td>3.278929</td>\n      <td>3.303571</td>\n      <td>3.223572</td>\n      <td>2.803923</td>\n      <td>753048800</td>\n      <td>AAPL</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3BUBySttKdi8"
   },
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(r'C:\\Users\\e0690420\\rl_forex\\finrl\\preprocessing\\datasets\\chicago_pmi\\EURUSD\\ohlc\\EURUSD_Chicago_Pmi_2018-01-31 - Copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "p4GvflUkKlO1",
    "outputId": "ec995ed2-8274-4efe-e51b-fa899f68752a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        time     open     high      low    close\n",
       "0  2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667\n",
       "1  2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667\n",
       "2  2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667\n",
       "3  2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667\n",
       "4  2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpAglfGjLfmC",
    "outputId": "e18d61bd-6a9b-42d8-f3b9-cc29af4e3e44"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       2018-01-31 13:45:00+00:00\n",
       "1       2018-01-31 13:45:01+00:00\n",
       "2       2018-01-31 13:45:02+00:00\n",
       "3       2018-01-31 13:45:03+00:00\n",
       "4       2018-01-31 13:45:04+00:00\n",
       "                  ...            \n",
       "7195    2018-01-31 15:44:55+00:00\n",
       "7196    2018-01-31 15:44:56+00:00\n",
       "7197    2018-01-31 15:44:57+00:00\n",
       "7198    2018-01-31 15:44:58+00:00\n",
       "7199    2018-01-31 15:44:59+00:00\n",
       "Name: time, Length: 7200, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6J9-bmQvMMNr"
   },
   "outputs": [],
   "source": [
    "data_df.rename(columns = {\"time\": \"date\"},  \n",
    "          inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "lcr5BuAGMTVE",
    "outputId": "75b264f5-742f-411e-bbaf-fb30dab18faa"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        date     open     high      low    close\n",
       "0  2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667\n",
       "1  2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667\n",
       "2  2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667\n",
       "3  2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667\n",
       "4  2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GBNU9jpjHaM",
    "outputId": "27850f15-55fe-4394-b908-a04b29cee418"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data_df['date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0vdGpmOBkGGw"
   },
   "outputs": [],
   "source": [
    "data_df.date = pd.to_datetime(data_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DauaiG9NkIyH",
    "outputId": "ecb3e95e-adf0-44c9-8388-66d63555a00d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data_df['date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "L92yOx4SjYfG"
   },
   "outputs": [],
   "source": [
    "data_df['day'] = data_df['date'].dt.dayofweek\n",
    "data_df['tic'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "CR6t24RRkMjR",
    "outputId": "98a4e9bc-aa76-426d-f2de-54acf363b7e1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       date     open     high      low    close  day tic\n",
       "0 2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667    2   A\n",
       "1 2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667    2   A\n",
       "2 2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667    2   A\n",
       "3 2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667    2   A\n",
       "4 2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667    2   A"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>day</th>\n      <th>tic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWiqgpLzTnS3"
   },
   "source": [
    "<a id='3'></a>\n",
    "# Part 4. Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* FinRL uses a class **FeatureEngineer** to preprocess the data\n",
    "* Add **technical indicators**. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ9zmxpRks41"
   },
   "source": [
    "class FeatureEngineer:\n",
    "Provides methods for preprocessing the stock price data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            data downloaded from Yahoo API\n",
    "        feature_number : int\n",
    "            number of features we used\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHu7i-T_wRPc"
   },
   "source": [
    "<a id='3.1'></a>\n",
    "\n",
    "## 4.1 Technical Indicators\n",
    "* FinRL uses stockstats to calcualte technical indicators such as **Moving Average Convergence Divergence (MACD)**, **Relative Strength Index (RSI)**, **Average Directional Index (ADX)**, **Commodity Channel Index (CCI)** and other various indicators and stats.\n",
    "* **stockstats**: supplies a wrapper StockDataFrame based on the **pandas.DataFrame** with inline stock statistics/indicators support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RHwY1dHk09N",
    "outputId": "50f20e93-efb8-46e4-fc85-75c1f2d5b747"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
     ]
    }
   ],
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "print(tech_indicator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rImfGAfCkR8j",
    "outputId": "1e9866ee-7922-4111-9379-b6d6de3ceece"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
     ]
    }
   ],
   "source": [
    "## user can add more technical indicators\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
    "print(tech_indicator_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etvRo2rSwZPg"
   },
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2 Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAOsx0m-9u2k",
    "outputId": "fd423728-f352-4cc5-de03-eeeb493d5c39"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicator_list,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "data_df = fe.preprocess_data(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "wytX_qwWMHP5",
    "outputId": "6393275a-4af3-42fb-8a65-417de9b701d1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       date     open     high      low    close  day tic  \\\n",
       "0 2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667    2   A   \n",
       "1 2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667    2   A   \n",
       "2 2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "3 2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "4 2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "\n",
       "   macd  boll_ub  boll_lb  ...  dx_30  close_30_sma  close_60_sma       kdjk  \\\n",
       "0   0.0  1.24667  1.24667  ...  100.0       1.24667       1.24667  66.666667   \n",
       "1   0.0  1.24667  1.24667  ...  100.0       1.24667       1.24667  55.555556   \n",
       "2   0.0  1.24667  1.24667  ...  100.0       1.24667       1.24667  48.148148   \n",
       "3   0.0  1.24667  1.24667  ...  100.0       1.24667       1.24667  43.209877   \n",
       "4   0.0  1.24667  1.24667  ...  100.0       1.24667       1.24667  39.917695   \n",
       "\n",
       "   open_2_sma     boll  close_10.0_le_5_c      wr_10  dma  trix  \n",
       "0    1.246660  1.24667                1.0   0.000000  0.0   0.0  \n",
       "1    1.246675  1.24667                2.0  66.666667  0.0   0.0  \n",
       "2    1.246680  1.24667                3.0  66.666667  0.0   0.0  \n",
       "3    1.246670  1.24667                4.0  66.666667  0.0   0.0  \n",
       "4    1.246670  1.24667                5.0  66.666667  0.0   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>day</th>\n      <th>tic</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>...</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>66.666667</td>\n      <td>1.246660</td>\n      <td>1.24667</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>55.555556</td>\n      <td>1.246675</td>\n      <td>1.24667</td>\n      <td>2.0</td>\n      <td>66.666667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>48.148148</td>\n      <td>1.246680</td>\n      <td>1.24667</td>\n      <td>3.0</td>\n      <td>66.666667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>43.209877</td>\n      <td>1.246670</td>\n      <td>1.24667</td>\n      <td>4.0</td>\n      <td>66.666667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>39.917695</td>\n      <td>1.246670</td>\n      <td>1.24667</td>\n      <td>5.0</td>\n      <td>66.666667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLhXo1cTnTQ"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D1FlBdOL4b3"
   },
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1 Training & Trade data split\n",
    "* Training: 2009-01-01 to 2018-12-31\n",
    "* Trade: 2019-01-01 to 2020-09-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xNOdqfTKL6K-"
   },
   "outputs": [],
   "source": [
    "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
    "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
    "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "S4VjAVopn9qr",
    "outputId": "bce1d416-79e5-42da-d894-1cd360dd2f6c"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          date     open     high      low    close  day tic  \\\n",
       "0    2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667    2   A   \n",
       "1    2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667    2   A   \n",
       "2    2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "3    2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "4    2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "...                        ...      ...      ...      ...      ...  ...  ..   \n",
       "7195 2018-01-31 15:44:55+00:00  1.24705  1.24705  1.24705  1.24705    2   A   \n",
       "7196 2018-01-31 15:44:56+00:00  1.24704  1.24707  1.24704  1.24707    2   A   \n",
       "7197 2018-01-31 15:44:57+00:00  1.24710  1.24710  1.24707  1.24707    2   A   \n",
       "7198 2018-01-31 15:44:58+00:00  1.24708  1.24708  1.24708  1.24708    2   A   \n",
       "7199 2018-01-31 15:44:59+00:00  1.24708  1.24708  1.24708  1.24708    2   A   \n",
       "\n",
       "          macd   boll_ub   boll_lb  ...       dx_30  close_30_sma  \\\n",
       "0     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "1     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "2     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "3     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "4     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "...        ...       ...       ...  ...         ...           ...   \n",
       "7195  0.000003  1.247152  1.247040  ...   12.137444      1.247089   \n",
       "7196  0.000003  1.247152  1.247038  ...    1.179734      1.247091   \n",
       "7197  0.000002  1.247150  1.247036  ...   12.526021      1.247092   \n",
       "7198  0.000003  1.247147  1.247035  ...   12.526021      1.247094   \n",
       "7199  0.000003  1.247145  1.247034  ...   12.526021      1.247093   \n",
       "\n",
       "      close_60_sma       kdjk  open_2_sma      boll  close_10.0_le_5_c  \\\n",
       "0         1.246670  66.666667    1.246660  1.246670                1.0   \n",
       "1         1.246670  55.555556    1.246675  1.246670                2.0   \n",
       "2         1.246670  48.148148    1.246680  1.246670                3.0   \n",
       "3         1.246670  43.209877    1.246670  1.246670                4.0   \n",
       "4         1.246670  39.917695    1.246670  1.246670                5.0   \n",
       "...            ...        ...         ...       ...                ...   \n",
       "7195      1.247022  13.127958    1.247060  1.247096                5.0   \n",
       "7196      1.247021  28.751972    1.247045  1.247095                5.0   \n",
       "7197      1.247020  35.834648    1.247070  1.247093                5.0   \n",
       "7198      1.247019  46.111988    1.247090  1.247091                5.0   \n",
       "7199      1.247018  52.963547    1.247080  1.247089                5.0   \n",
       "\n",
       "          wr_10       dma      trix  \n",
       "0      0.000000  0.000000  0.000000  \n",
       "1     66.666667  0.000000  0.000000  \n",
       "2     66.666667  0.000000  0.000000  \n",
       "3     66.666667  0.000000  0.000000  \n",
       "4     66.666667  0.000000  0.000000  \n",
       "...         ...       ...       ...  \n",
       "7195  80.000000  0.000060  0.000102  \n",
       "7196  40.000000  0.000055  0.000065  \n",
       "7197  50.000000  0.000050  0.000035  \n",
       "7198  33.333333  0.000046  0.000014  \n",
       "7199  33.333333  0.000043  0.000001  \n",
       "\n",
       "[7200 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>day</th>\n      <th>tic</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>...</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>66.666667</td>\n      <td>1.246660</td>\n      <td>1.246670</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>55.555556</td>\n      <td>1.246675</td>\n      <td>1.246670</td>\n      <td>2.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>48.148148</td>\n      <td>1.246680</td>\n      <td>1.246670</td>\n      <td>3.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>43.209877</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>4.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>39.917695</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>5.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7195</th>\n      <td>2018-01-31 15:44:55+00:00</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247152</td>\n      <td>1.247040</td>\n      <td>...</td>\n      <td>12.137444</td>\n      <td>1.247089</td>\n      <td>1.247022</td>\n      <td>13.127958</td>\n      <td>1.247060</td>\n      <td>1.247096</td>\n      <td>5.0</td>\n      <td>80.000000</td>\n      <td>0.000060</td>\n      <td>0.000102</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>2018-01-31 15:44:56+00:00</td>\n      <td>1.24704</td>\n      <td>1.24707</td>\n      <td>1.24704</td>\n      <td>1.24707</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247152</td>\n      <td>1.247038</td>\n      <td>...</td>\n      <td>1.179734</td>\n      <td>1.247091</td>\n      <td>1.247021</td>\n      <td>28.751972</td>\n      <td>1.247045</td>\n      <td>1.247095</td>\n      <td>5.0</td>\n      <td>40.000000</td>\n      <td>0.000055</td>\n      <td>0.000065</td>\n    </tr>\n    <tr>\n      <th>7197</th>\n      <td>2018-01-31 15:44:57+00:00</td>\n      <td>1.24710</td>\n      <td>1.24710</td>\n      <td>1.24707</td>\n      <td>1.24707</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000002</td>\n      <td>1.247150</td>\n      <td>1.247036</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247092</td>\n      <td>1.247020</td>\n      <td>35.834648</td>\n      <td>1.247070</td>\n      <td>1.247093</td>\n      <td>5.0</td>\n      <td>50.000000</td>\n      <td>0.000050</td>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>7198</th>\n      <td>2018-01-31 15:44:58+00:00</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247147</td>\n      <td>1.247035</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247094</td>\n      <td>1.247019</td>\n      <td>46.111988</td>\n      <td>1.247090</td>\n      <td>1.247091</td>\n      <td>5.0</td>\n      <td>33.333333</td>\n      <td>0.000046</td>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>7199</th>\n      <td>2018-01-31 15:44:59+00:00</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247145</td>\n      <td>1.247034</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247093</td>\n      <td>1.247018</td>\n      <td>52.963547</td>\n      <td>1.247080</td>\n      <td>1.247089</td>\n      <td>5.0</td>\n      <td>33.333333</td>\n      <td>0.000043</td>\n      <td>0.000001</td>\n    </tr>\n  </tbody>\n</table>\n<p>7200 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "Qk-0xNujnjb1",
    "outputId": "c2543f7b-283a-4387-877b-84a4292cbb68"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          date     open     high      low    close  day tic  \\\n",
       "0    2018-01-31 13:45:00+00:00  1.24666  1.24667  1.24666  1.24667    2   A   \n",
       "1    2018-01-31 13:45:01+00:00  1.24669  1.24669  1.24667  1.24667    2   A   \n",
       "2    2018-01-31 13:45:02+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "3    2018-01-31 13:45:03+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "4    2018-01-31 13:45:04+00:00  1.24667  1.24667  1.24667  1.24667    2   A   \n",
       "...                        ...      ...      ...      ...      ...  ...  ..   \n",
       "7195 2018-01-31 15:44:55+00:00  1.24705  1.24705  1.24705  1.24705    2   A   \n",
       "7196 2018-01-31 15:44:56+00:00  1.24704  1.24707  1.24704  1.24707    2   A   \n",
       "7197 2018-01-31 15:44:57+00:00  1.24710  1.24710  1.24707  1.24707    2   A   \n",
       "7198 2018-01-31 15:44:58+00:00  1.24708  1.24708  1.24708  1.24708    2   A   \n",
       "7199 2018-01-31 15:44:59+00:00  1.24708  1.24708  1.24708  1.24708    2   A   \n",
       "\n",
       "          macd   boll_ub   boll_lb  ...       dx_30  close_30_sma  \\\n",
       "0     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "1     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "2     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "3     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "4     0.000000  1.246670  1.246670  ...  100.000000      1.246670   \n",
       "...        ...       ...       ...  ...         ...           ...   \n",
       "7195  0.000003  1.247152  1.247040  ...   12.137444      1.247089   \n",
       "7196  0.000003  1.247152  1.247038  ...    1.179734      1.247091   \n",
       "7197  0.000002  1.247150  1.247036  ...   12.526021      1.247092   \n",
       "7198  0.000003  1.247147  1.247035  ...   12.526021      1.247094   \n",
       "7199  0.000003  1.247145  1.247034  ...   12.526021      1.247093   \n",
       "\n",
       "      close_60_sma       kdjk  open_2_sma      boll  close_10.0_le_5_c  \\\n",
       "0         1.246670  66.666667    1.246660  1.246670                1.0   \n",
       "1         1.246670  55.555556    1.246675  1.246670                2.0   \n",
       "2         1.246670  48.148148    1.246680  1.246670                3.0   \n",
       "3         1.246670  43.209877    1.246670  1.246670                4.0   \n",
       "4         1.246670  39.917695    1.246670  1.246670                5.0   \n",
       "...            ...        ...         ...       ...                ...   \n",
       "7195      1.247022  13.127958    1.247060  1.247096                5.0   \n",
       "7196      1.247021  28.751972    1.247045  1.247095                5.0   \n",
       "7197      1.247020  35.834648    1.247070  1.247093                5.0   \n",
       "7198      1.247019  46.111988    1.247090  1.247091                5.0   \n",
       "7199      1.247018  52.963547    1.247080  1.247089                5.0   \n",
       "\n",
       "          wr_10       dma      trix  \n",
       "0      0.000000  0.000000  0.000000  \n",
       "1     66.666667  0.000000  0.000000  \n",
       "2     66.666667  0.000000  0.000000  \n",
       "3     66.666667  0.000000  0.000000  \n",
       "4     66.666667  0.000000  0.000000  \n",
       "...         ...       ...       ...  \n",
       "7195  80.000000  0.000060  0.000102  \n",
       "7196  40.000000  0.000055  0.000065  \n",
       "7197  50.000000  0.000050  0.000035  \n",
       "7198  33.333333  0.000046  0.000014  \n",
       "7199  33.333333  0.000043  0.000001  \n",
       "\n",
       "[7200 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>day</th>\n      <th>tic</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>...</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-31 13:45:00+00:00</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>1.24666</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>66.666667</td>\n      <td>1.246660</td>\n      <td>1.246670</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-31 13:45:01+00:00</td>\n      <td>1.24669</td>\n      <td>1.24669</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>55.555556</td>\n      <td>1.246675</td>\n      <td>1.246670</td>\n      <td>2.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-31 13:45:02+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>48.148148</td>\n      <td>1.246680</td>\n      <td>1.246670</td>\n      <td>3.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-31 13:45:03+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>43.209877</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>4.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-31 13:45:04+00:00</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>1.24667</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>39.917695</td>\n      <td>1.246670</td>\n      <td>1.246670</td>\n      <td>5.0</td>\n      <td>66.666667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7195</th>\n      <td>2018-01-31 15:44:55+00:00</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>1.24705</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247152</td>\n      <td>1.247040</td>\n      <td>...</td>\n      <td>12.137444</td>\n      <td>1.247089</td>\n      <td>1.247022</td>\n      <td>13.127958</td>\n      <td>1.247060</td>\n      <td>1.247096</td>\n      <td>5.0</td>\n      <td>80.000000</td>\n      <td>0.000060</td>\n      <td>0.000102</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>2018-01-31 15:44:56+00:00</td>\n      <td>1.24704</td>\n      <td>1.24707</td>\n      <td>1.24704</td>\n      <td>1.24707</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247152</td>\n      <td>1.247038</td>\n      <td>...</td>\n      <td>1.179734</td>\n      <td>1.247091</td>\n      <td>1.247021</td>\n      <td>28.751972</td>\n      <td>1.247045</td>\n      <td>1.247095</td>\n      <td>5.0</td>\n      <td>40.000000</td>\n      <td>0.000055</td>\n      <td>0.000065</td>\n    </tr>\n    <tr>\n      <th>7197</th>\n      <td>2018-01-31 15:44:57+00:00</td>\n      <td>1.24710</td>\n      <td>1.24710</td>\n      <td>1.24707</td>\n      <td>1.24707</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000002</td>\n      <td>1.247150</td>\n      <td>1.247036</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247092</td>\n      <td>1.247020</td>\n      <td>35.834648</td>\n      <td>1.247070</td>\n      <td>1.247093</td>\n      <td>5.0</td>\n      <td>50.000000</td>\n      <td>0.000050</td>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>7198</th>\n      <td>2018-01-31 15:44:58+00:00</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247147</td>\n      <td>1.247035</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247094</td>\n      <td>1.247019</td>\n      <td>46.111988</td>\n      <td>1.247090</td>\n      <td>1.247091</td>\n      <td>5.0</td>\n      <td>33.333333</td>\n      <td>0.000046</td>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>7199</th>\n      <td>2018-01-31 15:44:59+00:00</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>1.24708</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0.000003</td>\n      <td>1.247145</td>\n      <td>1.247034</td>\n      <td>...</td>\n      <td>12.526021</td>\n      <td>1.247093</td>\n      <td>1.247018</td>\n      <td>52.963547</td>\n      <td>1.247080</td>\n      <td>1.247089</td>\n      <td>5.0</td>\n      <td>33.333333</td>\n      <td>0.000043</td>\n      <td>0.000001</td>\n    </tr>\n  </tbody>\n</table>\n<p>7200 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "BcxSFaATnxzf",
    "outputId": "5472f3e2-e11c-47de-bc78-2d8bafa6efe1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, open, high, low, close, day, tic, macd, boll_ub, boll_lb, rsi_30, cci_30, dx_30, close_30_sma, close_60_sma, kdjk, open_2_sma, boll, close_10.0_le_5_c, wr_10, dma, trix]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>day</th>\n      <th>tic</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>...</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KUxOshVouLXt"
   },
   "outputs": [],
   "source": [
    "## data normalization, this part is optional, have little impact\n",
    "#feaures_list = list(train.columns)\n",
    "#feaures_list.remove('date')\n",
    "#feaures_list.remove('tic')\n",
    "#feaures_list.remove('close')\n",
    "#print(feaures_list)\n",
    "#from sklearn import preprocessing\n",
    "#data_normaliser = preprocessing.StandardScaler()\n",
    "#train[feaures_list] = data_normaliser.fit_transform(train[feaures_list])\n",
    "#trade[feaures_list] = data_normaliser.transform(trade[feaures_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMHyaSBBDGbe"
   },
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2 User-defined Environment: a simulation environment class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90V3S7cpDcQs"
   },
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3 Initialize Environment\n",
    "* **stock dimension**: the number of unique stock tickers we use\n",
    "* **hmax**: the maximum amount of shares to buy or sell\n",
    "* **initial amount**: the amount of money we use to trade in the begining\n",
    "* **transaction cost percentage**: a per share rate for every share trade\n",
    "* **tech_indicator_list**: a list of technical indicator names (modified from config.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiH0xO96mGcL",
    "outputId": "cebba4e4-a5db-4cab-aa31-3d4a5dd60c40"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma',\n",
       " 'kdjk',\n",
       " 'open_2_sma',\n",
       " 'boll',\n",
       " 'close_10.0_le_5_c',\n",
       " 'wr_10',\n",
       " 'dma',\n",
       " 'trix']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnWOKS7DyGM7",
    "outputId": "f56d08be-6f7b-4a23-c85c-d0afdfffd8fb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# the stock dimension is 1, because we only use the price data of AAPL.\n",
    "len(train.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJcnLvQGAba",
    "outputId": "7f4c2b05-3535-450c-8161-f128f801ceab"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JY5wTwYjGTrg"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'transaction_cost_pct'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-8f3a4f4c5b4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0me_train_gym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0menv_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'transaction_cost_pct'"
     ]
    }
   ],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 100000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmyi2IPnyEkP",
    "outputId": "bc1b14c5-9f2d-46ed-e383-435a7fed03ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdnzYtM1TnTW"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRFIZDw8TnTX"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD1NHzGyTnTc"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CM5DeIr9GC"
   },
   "source": [
    "### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOk-Mr73-EEq",
    "outputId": "e02c31b4-cf24-49dd-86c9-c938f839a6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0001}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXHEidJh-E60",
    "outputId": "8e625d17-0e85-4179-81a7-a3b616da94ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c/a2c_3\n",
      "day: 95, episode: 2860\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99911.01\n",
      "total_reward: -88.99\n",
      "total_cost: 6.70\n",
      "total_trades: 95\n",
      "Sharpe: -2.510\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+04 |\n",
      "|    total_cost         | 6.73     |\n",
      "|    total_reward       | -59.8    |\n",
      "|    total_reward_pct   | -0.0598  |\n",
      "|    total_trades       | 92       |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.000149 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.35e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.99e+04  |\n",
      "|    total_cost         | 6.94      |\n",
      "|    total_reward       | -97.8     |\n",
      "|    total_reward_pct   | -0.0978   |\n",
      "|    total_trades       | 93        |\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.44     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.000313 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.42e-07  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2870\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99961.39\n",
      "total_reward: -38.61\n",
      "total_cost: 6.50\n",
      "total_trades: 93\n",
      "Sharpe: -2.207\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 6.58     |\n",
      "|    total_reward       | -40.5    |\n",
      "|    total_reward_pct   | -0.0405  |\n",
      "|    total_trades       | 90       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 2.43e-05 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.33e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 5.74      |\n",
      "|    total_reward       | -45.4     |\n",
      "|    total_reward_pct   | -0.0454   |\n",
      "|    total_trades       | 87        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -6.21e+13 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -0.00292  |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.63e-06  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2880\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99946.96\n",
      "total_reward: -53.04\n",
      "total_cost: 5.97\n",
      "total_trades: 92\n",
      "Sharpe: -3.082\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 6.43      |\n",
      "|    total_reward       | -29.8     |\n",
      "|    total_reward_pct   | -0.0298   |\n",
      "|    total_trades       | 92        |\n",
      "| time/                 |           |\n",
      "|    fps                | 366       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.000587 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.21e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 6.63     |\n",
      "|    total_reward       | -29.7    |\n",
      "|    total_reward_pct   | -0.0297  |\n",
      "|    total_trades       | 92       |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.00028  |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.24e-08 |\n",
      "------------------------------------\n",
      "day: 95, episode: 2890\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99977.40\n",
      "total_reward: -22.60\n",
      "total_cost: 6.29\n",
      "total_trades: 91\n",
      "Sharpe: -3.665\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 4.77      |\n",
      "|    total_reward       | -17.9     |\n",
      "|    total_reward_pct   | -0.0179   |\n",
      "|    total_trades       | 82        |\n",
      "| time/                 |           |\n",
      "|    fps                | 367       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.49     |\n",
      "|    explained_variance | -4.65e+10 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 0.00123   |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.04e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 5.27      |\n",
      "|    total_reward       | -8.07     |\n",
      "|    total_reward_pct   | -0.00807  |\n",
      "|    total_trades       | 86        |\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.5      |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -0.000275 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.62e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2900\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99987.09\n",
      "total_reward: -12.91\n",
      "total_cost: 3.70\n",
      "total_trades: 72\n",
      "Sharpe: -4.041\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 5.17     |\n",
      "|    total_reward       | -29.8    |\n",
      "|    total_reward_pct   | -0.0298  |\n",
      "|    total_trades       | 85       |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.000288 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 5.38e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 5.5       |\n",
      "|    total_reward       | -25.1     |\n",
      "|    total_reward_pct   | -0.0251   |\n",
      "|    total_trades       | 82        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.52     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.000252 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 4.02e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2910\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99970.51\n",
      "total_reward: -29.49\n",
      "total_cost: 5.25\n",
      "total_trades: 86\n",
      "Sharpe: -3.009\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 4.97      |\n",
      "|    total_reward       | -17       |\n",
      "|    total_reward_pct   | -0.017    |\n",
      "|    total_trades       | 79        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.000646 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 9.27e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 5.96      |\n",
      "|    total_reward       | -27.4     |\n",
      "|    total_reward_pct   | -0.0274   |\n",
      "|    total_trades       | 90        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -8.55e-06 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.77e-10  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2920\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99979.74\n",
      "total_reward: -20.26\n",
      "total_cost: 5.83\n",
      "total_trades: 88\n",
      "Sharpe: -4.153\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 5.94     |\n",
      "|    total_reward       | -23.8    |\n",
      "|    total_reward_pct   | -0.0238  |\n",
      "|    total_trades       | 81       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 2.48e-05 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 6.53e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 5.68     |\n",
      "|    total_reward       | -28.1    |\n",
      "|    total_reward_pct   | -0.0281  |\n",
      "|    total_trades       | 79       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 3.6e-05  |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 3e-09    |\n",
      "------------------------------------\n",
      "day: 95, episode: 2930\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99972.05\n",
      "total_reward: -27.95\n",
      "total_cost: 5.42\n",
      "total_trades: 83\n",
      "Sharpe: -2.840\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.48      |\n",
      "|    total_reward       | -8.68     |\n",
      "|    total_reward_pct   | -0.00868  |\n",
      "|    total_trades       | 72        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.57     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -0.000981 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.67e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 4.31      |\n",
      "|    total_reward       | -10.3     |\n",
      "|    total_reward_pct   | -0.0103   |\n",
      "|    total_trades       | 79        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.58     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -7.38e-06 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 8.13e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2940\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99989.70\n",
      "total_reward: -10.30\n",
      "total_cost: 2.56\n",
      "total_trades: 65\n",
      "Sharpe: -3.017\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.67     |\n",
      "|    total_reward       | -10.9    |\n",
      "|    total_reward_pct   | -0.0109  |\n",
      "|    total_trades       | 73       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 4.23e-05 |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 4.55e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.8      |\n",
      "|    total_reward       | -1.71    |\n",
      "|    total_reward_pct   | -0.00171 |\n",
      "|    total_trades       | 61       |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.51e-05 |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 1.71e-10 |\n",
      "------------------------------------\n",
      "day: 95, episode: 2950\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.89\n",
      "total_reward: -5.11\n",
      "total_cost: 2.94\n",
      "total_trades: 57\n",
      "Sharpe: -4.824\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 5.06      |\n",
      "|    total_reward       | -34.5     |\n",
      "|    total_reward_pct   | -0.0345   |\n",
      "|    total_trades       | 87        |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.61     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -5.09e-05 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 1.23e-09  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 2960\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99985.73\n",
      "total_reward: -14.27\n",
      "total_cost: 3.82\n",
      "total_trades: 76\n",
      "Sharpe: -2.973\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.82      |\n",
      "|    total_reward       | -14.3     |\n",
      "|    total_reward_pct   | -0.0143   |\n",
      "|    total_trades       | 76        |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.62     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -0.000645 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 1.37e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 5.04     |\n",
      "|    total_reward       | -15.2    |\n",
      "|    total_reward_pct   | -0.0152  |\n",
      "|    total_trades       | 81       |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.63    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -6.1e-06 |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 3.29e-11 |\n",
      "------------------------------------\n",
      "day: 95, episode: 2970\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99983.29\n",
      "total_reward: -16.71\n",
      "total_cost: 3.26\n",
      "total_trades: 66\n",
      "Sharpe: -2.418\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.26      |\n",
      "|    total_reward       | -16.7     |\n",
      "|    total_reward_pct   | -0.0167   |\n",
      "|    total_trades       | 66        |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.64     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -3.06e-05 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 7.7e-10   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.19     |\n",
      "|    total_reward       | -7.95    |\n",
      "|    total_reward_pct   | -0.00795 |\n",
      "|    total_trades       | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 4.26e-06 |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 7.7e-12  |\n",
      "------------------------------------\n",
      "day: 95, episode: 2980\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.50\n",
      "total_reward: -7.50\n",
      "total_cost: 4.19\n",
      "total_trades: 71\n",
      "Sharpe: -3.679\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.75     |\n",
      "|    total_reward       | -4.62    |\n",
      "|    total_reward_pct   | -0.00462 |\n",
      "|    total_trades       | 63       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 4.07e-05 |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 1.57e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.45     |\n",
      "|    total_reward       | -11      |\n",
      "|    total_reward_pct   | -0.011   |\n",
      "|    total_trades       | 57       |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.000277 |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 4.68e-08 |\n",
      "------------------------------------\n",
      "day: 95, episode: 2990\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99993.60\n",
      "total_reward: -6.40\n",
      "total_cost: 3.60\n",
      "total_trades: 66\n",
      "Sharpe: -3.232\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 4.78     |\n",
      "|    total_reward       | -6.75    |\n",
      "|    total_reward_pct   | -0.00675 |\n",
      "|    total_trades       | 77       |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 2.01e-05 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 1.28e-10 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.22      |\n",
      "|    total_reward       | -3.43     |\n",
      "|    total_reward_pct   | -0.00343  |\n",
      "|    total_trades       | 49        |\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.69     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -1.09e-05 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 6.95e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3000\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99989.03\n",
      "total_reward: -10.97\n",
      "total_cost: 3.21\n",
      "total_trades: 60\n",
      "Sharpe: -3.665\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.85     |\n",
      "|    total_reward       | -6.27    |\n",
      "|    total_reward_pct   | -0.00627 |\n",
      "|    total_trades       | 56       |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 1.47e-05 |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 1.26e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.68     |\n",
      "|    total_reward       | -2.83    |\n",
      "|    total_reward_pct   | -0.00283 |\n",
      "|    total_trades       | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 5.55e-06 |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 1.77e-11 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3010\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.60\n",
      "total_reward: -1.40\n",
      "total_cost: 3.20\n",
      "total_trades: 69\n",
      "Sharpe: -0.520\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.26      |\n",
      "|    total_reward       | -4.62     |\n",
      "|    total_reward_pct   | -0.00462  |\n",
      "|    total_trades       | 56        |\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.72     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -4.68e-05 |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 5.25e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 4.09     |\n",
      "|    total_reward       | -1.06    |\n",
      "|    total_reward_pct   | -0.00106 |\n",
      "|    total_trades       | 68       |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.000135 |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 9.58e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3020\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99982.01\n",
      "total_reward: -17.99\n",
      "total_cost: 5.01\n",
      "total_trades: 78\n",
      "Sharpe: -2.969\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.85      |\n",
      "|    total_reward       | -6.82     |\n",
      "|    total_reward_pct   | -0.00682  |\n",
      "|    total_trades       | 57        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -1.37e-05 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 1.22e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.8      |\n",
      "|    total_reward       | -4.96    |\n",
      "|    total_reward_pct   | -0.00496 |\n",
      "|    total_trades       | 74       |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 7.72e-06 |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 2.97e-11 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3030\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99990.50\n",
      "total_reward: -9.50\n",
      "total_cost: 2.28\n",
      "total_trades: 46\n",
      "Sharpe: -2.842\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.53     |\n",
      "|    total_reward       | -15.7    |\n",
      "|    total_reward_pct   | -0.0157  |\n",
      "|    total_trades       | 61       |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0017   |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 3.66e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.4       |\n",
      "|    total_reward       | -3.52     |\n",
      "|    total_reward_pct   | -0.00352  |\n",
      "|    total_trades       | 59        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.77     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -0.000349 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 4.78e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3040\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99996.12\n",
      "total_reward: -3.88\n",
      "total_cost: 2.58\n",
      "total_trades: 52\n",
      "Sharpe: -7.817\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 4.55      |\n",
      "|    total_reward       | -8.04     |\n",
      "|    total_reward_pct   | -0.00804  |\n",
      "|    total_trades       | 66        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.78     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -2.67e-05 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 3.81e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 4.34     |\n",
      "|    total_reward       | -8.59    |\n",
      "|    total_reward_pct   | -0.00859 |\n",
      "|    total_trades       | 67       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 8.66e-05 |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 3.57e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3050\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99990.53\n",
      "total_reward: -9.47\n",
      "total_cost: 2.48\n",
      "total_trades: 54\n",
      "Sharpe: -3.596\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.64      |\n",
      "|    total_reward       | -10.7     |\n",
      "|    total_reward_pct   | -0.0107   |\n",
      "|    total_trades       | 56        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.8      |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -2.33e-05 |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 1.12e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.72      |\n",
      "|    total_reward       | -10.4     |\n",
      "|    total_reward_pct   | -0.0104   |\n",
      "|    total_trades       | 61        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.81     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -0.000376 |\n",
      "|    std                | 1.48      |\n",
      "|    value_loss         | 6.29e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3060\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99995.54\n",
      "total_reward: -4.46\n",
      "total_cost: 2.47\n",
      "total_trades: 53\n",
      "Sharpe: -3.134\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.7       |\n",
      "|    total_reward       | -2.08     |\n",
      "|    total_reward_pct   | -0.00208  |\n",
      "|    total_trades       | 59        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.82     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -0.000203 |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 2.17e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 4.11      |\n",
      "|    total_reward       | -15.5     |\n",
      "|    total_reward_pct   | -0.0155   |\n",
      "|    total_trades       | 68        |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.83     |\n",
      "|    explained_variance | -2.57e+10 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 9.12e-05  |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.97e-09  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3070\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.69\n",
      "total_reward: -11.31\n",
      "total_cost: 2.46\n",
      "total_trades: 52\n",
      "Sharpe: -3.747\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.63      |\n",
      "|    total_reward       | -15.8     |\n",
      "|    total_reward_pct   | -0.0158   |\n",
      "|    total_trades       | 63        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.84     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -7.92e-06 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 7.95e-11  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.43     |\n",
      "|    total_reward       | -9.19    |\n",
      "|    total_reward_pct   | -0.00919 |\n",
      "|    total_trades       | 54       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.85    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.49e-05 |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 1.14e-10 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3080\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99987.17\n",
      "total_reward: -12.83\n",
      "total_cost: 2.69\n",
      "total_trades: 57\n",
      "Sharpe: -3.356\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.11     |\n",
      "|    total_reward       | -4.59    |\n",
      "|    total_reward_pct   | -0.00459 |\n",
      "|    total_trades       | 49       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 7.88e-05 |\n",
      "|    std                | 1.55     |\n",
      "|    value_loss         | 2.15e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3090\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99984.57\n",
      "total_reward: -15.43\n",
      "total_cost: 3.90\n",
      "total_trades: 58\n",
      "Sharpe: -2.397\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.9      |\n",
      "|    total_reward       | -15.4    |\n",
      "|    total_reward_pct   | -0.0154  |\n",
      "|    total_trades       | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.000315 |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 5.56e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.67     |\n",
      "|    total_reward       | -4.65    |\n",
      "|    total_reward_pct   | -0.00465 |\n",
      "|    total_trades       | 34       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.88    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 2.18e-06 |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 4.4e-12  |\n",
      "------------------------------------\n",
      "day: 95, episode: 3100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99990.06\n",
      "total_reward: -9.94\n",
      "total_cost: 2.80\n",
      "total_trades: 55\n",
      "Sharpe: -3.115\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.8       |\n",
      "|    total_reward       | -9.94     |\n",
      "|    total_reward_pct   | -0.00994  |\n",
      "|    total_trades       | 55        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.89     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -6.36e-06 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 2.34e-11  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.35     |\n",
      "|    total_reward       | -11.1    |\n",
      "|    total_reward_pct   | -0.0111  |\n",
      "|    total_trades       | 54       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 7.35e-05 |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 2.15e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.05\n",
      "total_reward: -1.95\n",
      "total_cost: 1.78\n",
      "total_trades: 45\n",
      "Sharpe: -2.357\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.79     |\n",
      "|    total_reward       | -8.06    |\n",
      "|    total_reward_pct   | -0.00806 |\n",
      "|    total_trades       | 42       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.000266 |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 3.25e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.94      |\n",
      "|    total_reward       | -5.97     |\n",
      "|    total_reward_pct   | -0.00597  |\n",
      "|    total_trades       | 42        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.92     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -1.07e-05 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 3.52e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.67\n",
      "total_reward: -2.33\n",
      "total_cost: 1.60\n",
      "total_trades: 36\n",
      "Sharpe: -4.466\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.56     |\n",
      "|    total_reward       | -6.09    |\n",
      "|    total_reward_pct   | -0.00609 |\n",
      "|    total_trades       | 50       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.93    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 3.43e-05 |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 2.87e-10 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.12      |\n",
      "|    total_reward       | -11.7     |\n",
      "|    total_reward_pct   | -0.0117   |\n",
      "|    total_trades       | 59        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.94     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -0.000264 |\n",
      "|    std                | 1.68      |\n",
      "|    value_loss         | 3.46e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99993.85\n",
      "total_reward: -6.15\n",
      "total_cost: 2.03\n",
      "total_trades: 48\n",
      "Sharpe: -2.904\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.88      |\n",
      "|    total_reward       | -4.06     |\n",
      "|    total_reward_pct   | -0.00406  |\n",
      "|    total_trades       | 38        |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.95     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -2.91e-05 |\n",
      "|    std                | 1.7       |\n",
      "|    value_loss         | 2.64e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.84     |\n",
      "|    total_reward       | -12.6    |\n",
      "|    total_reward_pct   | -0.0126  |\n",
      "|    total_trades       | 41       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.000106 |\n",
      "|    std                | 1.71     |\n",
      "|    value_loss         | 2.65e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.56\n",
      "total_reward: -2.44\n",
      "total_cost: 1.46\n",
      "total_trades: 37\n",
      "Sharpe: -5.609\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.74     |\n",
      "|    total_reward       | -7.61    |\n",
      "|    total_reward_pct   | -0.00761 |\n",
      "|    total_trades       | 36       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.000559 |\n",
      "|    std                | 1.73     |\n",
      "|    value_loss         | 1.19e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.11      |\n",
      "|    total_reward       | -6.03     |\n",
      "|    total_reward_pct   | -0.00603  |\n",
      "|    total_trades       | 58        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.98     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -9.99e-05 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 4.11e-09  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.78\n",
      "total_reward: -5.22\n",
      "total_cost: 2.34\n",
      "total_trades: 47\n",
      "Sharpe: -4.371\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.29     |\n",
      "|    total_reward       | -6.87    |\n",
      "|    total_reward_pct   | -0.00687 |\n",
      "|    total_trades       | 47       |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.99    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 3.42e-05 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 3.83e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.31     |\n",
      "|    total_reward       | -7.81    |\n",
      "|    total_reward_pct   | -0.00781 |\n",
      "|    total_trades       | 48       |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.000517 |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 1.37e-07 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99996.41\n",
      "total_reward: -3.59\n",
      "total_cost: 1.86\n",
      "total_trades: 38\n",
      "Sharpe: -5.990\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.91     |\n",
      "|    total_reward       | -6.11    |\n",
      "|    total_reward_pct   | -0.00611 |\n",
      "|    total_trades       | 36       |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.01    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.00028 |\n",
      "|    std                | 1.8      |\n",
      "|    value_loss         | 3.01e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.82      |\n",
      "|    total_reward       | -8.73     |\n",
      "|    total_reward_pct   | -0.00873  |\n",
      "|    total_trades       | 43        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.02     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -0.000272 |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 1.82e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99991.84\n",
      "total_reward: -8.16\n",
      "total_cost: 2.08\n",
      "total_trades: 43\n",
      "Sharpe: -3.851\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.39      |\n",
      "|    total_reward       | -1.88     |\n",
      "|    total_reward_pct   | -0.00188  |\n",
      "|    total_trades       | 47        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.03     |\n",
      "|    explained_variance | -2.95e+10 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 0.00028   |\n",
      "|    std                | 1.84      |\n",
      "|    value_loss         | 3.3e-08   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.82      |\n",
      "|    total_reward       | -5.51     |\n",
      "|    total_reward_pct   | -0.00551  |\n",
      "|    total_trades       | 57        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.04     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -0.000123 |\n",
      "|    std                | 1.86      |\n",
      "|    value_loss         | 5.56e-09  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.54\n",
      "total_reward: -7.46\n",
      "total_cost: 1.91\n",
      "total_trades: 46\n",
      "Sharpe: -3.331\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.27      |\n",
      "|    total_reward       | -2.3      |\n",
      "|    total_reward_pct   | -0.0023   |\n",
      "|    total_trades       | 46        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.05     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -0.000591 |\n",
      "|    std                | 1.88      |\n",
      "|    value_loss         | 9.96e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.45      |\n",
      "|    total_reward       | -1.54     |\n",
      "|    total_reward_pct   | -0.00154  |\n",
      "|    total_trades       | 36        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.06     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -2.68e-05 |\n",
      "|    std                | 1.89      |\n",
      "|    value_loss         | 2.22e-10  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.75\n",
      "total_reward: -5.25\n",
      "total_cost: 1.54\n",
      "total_trades: 41\n",
      "Sharpe: -3.179\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.25      |\n",
      "|    total_reward       | -8.91     |\n",
      "|    total_reward_pct   | -0.00891  |\n",
      "|    total_trades       | 52        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.07     |\n",
      "|    explained_variance | -5.7e+10  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -0.000112 |\n",
      "|    std                | 1.91      |\n",
      "|    value_loss         | 4.02e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.01      |\n",
      "|    total_reward       | -6.48     |\n",
      "|    total_reward_pct   | -0.00648  |\n",
      "|    total_trades       | 43        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -5.82e-05 |\n",
      "|    std                | 1.93      |\n",
      "|    value_loss         | 1.72e-09  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99990.40\n",
      "total_reward: -9.60\n",
      "total_cost: 2.57\n",
      "total_trades: 53\n",
      "Sharpe: -4.616\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 3.88      |\n",
      "|    total_reward       | -11.3     |\n",
      "|    total_reward_pct   | -0.0113   |\n",
      "|    total_trades       | 64        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.09     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -4.13e-05 |\n",
      "|    std                | 1.95      |\n",
      "|    value_loss         | 5.02e-10  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.38\n",
      "total_reward: -2.62\n",
      "total_cost: 1.73\n",
      "total_trades: 36\n",
      "Sharpe: -3.369\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.73     |\n",
      "|    total_reward       | -2.62    |\n",
      "|    total_reward_pct   | -0.00262 |\n",
      "|    total_trades       | 36       |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.00125 |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 5.26e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.38      |\n",
      "|    total_reward       | -4.44     |\n",
      "|    total_reward_pct   | -0.00444  |\n",
      "|    total_trades       | 35        |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.11     |\n",
      "|    explained_variance | -3.45e+10 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 0.000376  |\n",
      "|    std                | 1.99      |\n",
      "|    value_loss         | 3.96e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.44\n",
      "total_reward: -7.56\n",
      "total_cost: 2.80\n",
      "total_trades: 57\n",
      "Sharpe: -5.477\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.8      |\n",
      "|    total_reward       | -7.56    |\n",
      "|    total_reward_pct   | -0.00756 |\n",
      "|    total_trades       | 57       |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 2.6e-05  |\n",
      "|    std                | 2.01     |\n",
      "|    value_loss         | 2.3e-10  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.11      |\n",
      "|    total_reward       | -3.59     |\n",
      "|    total_reward_pct   | -0.00359  |\n",
      "|    total_trades       | 27        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.13     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -2.73e-06 |\n",
      "|    std                | 2.03      |\n",
      "|    value_loss         | 1.31e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.30\n",
      "total_reward: -11.70\n",
      "total_cost: 3.16\n",
      "total_trades: 51\n",
      "Sharpe: -2.927\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.32      |\n",
      "|    total_reward       | -6.75     |\n",
      "|    total_reward_pct   | -0.00675  |\n",
      "|    total_trades       | 32        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.14     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -6.25e-06 |\n",
      "|    std                | 2.05      |\n",
      "|    value_loss         | 2.85e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.3      |\n",
      "|    total_reward       | -1.68    |\n",
      "|    total_reward_pct   | -0.00168 |\n",
      "|    total_trades       | 32       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 6.98e-06 |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 6.07e-11 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.14\n",
      "total_reward: -0.86\n",
      "total_cost: 1.39\n",
      "total_trades: 36\n",
      "Sharpe: -1.032\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.55     |\n",
      "|    total_reward       | -4.37    |\n",
      "|    total_reward_pct   | -0.00437 |\n",
      "|    total_trades       | 48       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 1.28e-06 |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 6.62e-11 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.52     |\n",
      "|    total_reward       | -1.74    |\n",
      "|    total_reward_pct   | -0.00174 |\n",
      "|    total_trades       | 35       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 3.09e-05 |\n",
      "|    std                | 2.11     |\n",
      "|    value_loss         | 2.6e-10  |\n",
      "------------------------------------\n",
      "day: 95, episode: 3250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.17\n",
      "total_reward: -5.83\n",
      "total_cost: 3.25\n",
      "total_trades: 55\n",
      "Sharpe: -3.443\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1        |\n",
      "|    total_reward       | -2.23    |\n",
      "|    total_reward_pct   | -0.00223 |\n",
      "|    total_trades       | 23       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 1.43e-05 |\n",
      "|    std                | 2.14     |\n",
      "|    value_loss         | 8.28e-11 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.63      |\n",
      "|    total_reward       | -12.6     |\n",
      "|    total_reward_pct   | -0.0126   |\n",
      "|    total_trades       | 35        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -3.15e-05 |\n",
      "|    std                | 2.16      |\n",
      "|    value_loss         | 3.1e-10   |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99996.99\n",
      "total_reward: -3.01\n",
      "total_cost: 1.34\n",
      "total_trades: 32\n",
      "Sharpe: -5.189\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.66      |\n",
      "|    total_reward       | -4.49     |\n",
      "|    total_reward_pct   | -0.00449  |\n",
      "|    total_trades       | 35        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.2      |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -0.000329 |\n",
      "|    std                | 2.18      |\n",
      "|    value_loss         | 2.17e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.89     |\n",
      "|    total_reward       | -4.69    |\n",
      "|    total_reward_pct   | -0.00469 |\n",
      "|    total_trades       | 46       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 3.97e-05 |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 4.21e-10 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.00\n",
      "total_reward: -6.00\n",
      "total_cost: 1.78\n",
      "total_trades: 36\n",
      "Sharpe: -3.903\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.99      |\n",
      "|    total_reward       | -2.63     |\n",
      "|    total_reward_pct   | -0.00263  |\n",
      "|    total_trades       | 45        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.22     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -9.45e-05 |\n",
      "|    std                | 2.22      |\n",
      "|    value_loss         | 3.22e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.3      |\n",
      "|    total_reward       | -3.8     |\n",
      "|    total_reward_pct   | -0.0038  |\n",
      "|    total_trades       | 42       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.000631 |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 7.96e-08 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99981.02\n",
      "total_reward: -18.98\n",
      "total_cost: 3.73\n",
      "total_trades: 51\n",
      "Sharpe: -4.289\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.88     |\n",
      "|    total_reward       | -10.5    |\n",
      "|    total_reward_pct   | -0.0105  |\n",
      "|    total_trades       | 37       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.0003   |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 6.37e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.43     |\n",
      "|    total_reward       | -6.36    |\n",
      "|    total_reward_pct   | -0.00636 |\n",
      "|    total_trades       | 44       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.000194 |\n",
      "|    std                | 2.29     |\n",
      "|    value_loss         | 7.02e-09 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.49\n",
      "total_reward: -5.51\n",
      "total_cost: 2.04\n",
      "total_trades: 40\n",
      "Sharpe: -3.068\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.26      |\n",
      "|    total_reward       | -10.4     |\n",
      "|    total_reward_pct   | -0.0104   |\n",
      "|    total_trades       | 44        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.26     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -2.67e-05 |\n",
      "|    std                | 2.31      |\n",
      "|    value_loss         | 2.64e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.24     |\n",
      "|    total_reward       | -1.49    |\n",
      "|    total_reward_pct   | -0.00149 |\n",
      "|    total_trades       | 27       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 7.28e-05 |\n",
      "|    std                | 2.33     |\n",
      "|    value_loss         | 1.5e-09  |\n",
      "------------------------------------\n",
      "day: 95, episode: 3300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.52\n",
      "total_reward: -7.48\n",
      "total_cost: 1.91\n",
      "total_trades: 38\n",
      "Sharpe: -2.664\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.53      |\n",
      "|    total_reward       | -3.14     |\n",
      "|    total_reward_pct   | -0.00314  |\n",
      "|    total_trades       | 38        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.28     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -0.000481 |\n",
      "|    std                | 2.36      |\n",
      "|    value_loss         | 5e-08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.76      |\n",
      "|    total_reward       | -13.7     |\n",
      "|    total_reward_pct   | -0.0137   |\n",
      "|    total_trades       | 42        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.29     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -0.000415 |\n",
      "|    std                | 2.38      |\n",
      "|    value_loss         | 2.81e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.22\n",
      "total_reward: -5.78\n",
      "total_cost: 1.35\n",
      "total_trades: 25\n",
      "Sharpe: -2.622\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.07      |\n",
      "|    total_reward       | -6.91     |\n",
      "|    total_reward_pct   | -0.00691  |\n",
      "|    total_trades       | 43        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.3      |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -2.01e-05 |\n",
      "|    std                | 2.41      |\n",
      "|    value_loss         | 1.05e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 2.33     |\n",
      "|    total_reward       | -5.32    |\n",
      "|    total_reward_pct   | -0.00532 |\n",
      "|    total_trades       | 39       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.31    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 1.53e-05 |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 6.84e-11 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.09\n",
      "total_reward: -11.91\n",
      "total_cost: 2.21\n",
      "total_trades: 38\n",
      "Sharpe: -2.029\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.35      |\n",
      "|    total_reward       | -9.02     |\n",
      "|    total_reward_pct   | -0.00902  |\n",
      "|    total_trades       | 41        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.32     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -1.03e-05 |\n",
      "|    std                | 2.45      |\n",
      "|    value_loss         | 2.49e-11  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.53      |\n",
      "|    total_reward       | -5.82     |\n",
      "|    total_reward_pct   | -0.00582  |\n",
      "|    total_trades       | 34        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.33     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -4.68e-05 |\n",
      "|    std                | 2.48      |\n",
      "|    value_loss         | 6.3e-10   |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.82\n",
      "total_reward: -1.18\n",
      "total_cost: 2.16\n",
      "total_trades: 37\n",
      "Sharpe: -1.144\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.11      |\n",
      "|    total_reward       | -2.89     |\n",
      "|    total_reward_pct   | -0.00289  |\n",
      "|    total_trades       | 31        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.34     |\n",
      "|    explained_variance | -4.08e+10 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 0.000241  |\n",
      "|    std                | 2.5       |\n",
      "|    value_loss         | 1.34e-08  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99984.64\n",
      "total_reward: -15.36\n",
      "total_cost: 3.06\n",
      "total_trades: 40\n",
      "Sharpe: -2.256\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 3.06     |\n",
      "|    total_reward       | -15.4    |\n",
      "|    total_reward_pct   | -0.0154  |\n",
      "|    total_trades       | 40       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.000397 |\n",
      "|    std                | 2.53     |\n",
      "|    value_loss         | 4.38e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 2.97      |\n",
      "|    total_reward       | -6.17     |\n",
      "|    total_reward_pct   | -0.00617  |\n",
      "|    total_trades       | 48        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.36     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -1.43e-05 |\n",
      "|    std                | 2.55      |\n",
      "|    value_loss         | 4.38e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.84\n",
      "total_reward: 0.84\n",
      "total_cost: 1.02\n",
      "total_trades: 28\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.02      |\n",
      "|    total_reward       | 0.842     |\n",
      "|    total_reward_pct   | 0.000842  |\n",
      "|    total_trades       | 28        |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.37     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -1.62e-05 |\n",
      "|    std                | 2.58      |\n",
      "|    value_loss         | 1e-10     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.7      |\n",
      "|    total_reward       | -3.81    |\n",
      "|    total_reward_pct   | -0.00381 |\n",
      "|    total_trades       | 32       |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.000184 |\n",
      "|    std                | 2.6      |\n",
      "|    value_loss         | 1.17e-08 |\n",
      "------------------------------------\n",
      "day: 95, episode: 3360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99995.39\n",
      "total_reward: -4.61\n",
      "total_cost: 2.38\n",
      "total_trades: 39\n",
      "Sharpe: -4.970\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.42     |\n",
      "|    total_reward       | -3.23    |\n",
      "|    total_reward_pct   | -0.00323 |\n",
      "|    total_trades       | 34       |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.39    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 9.57e-05 |\n",
      "|    std                | 2.63     |\n",
      "|    value_loss         | 2.45e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+05     |\n",
      "|    total_cost         | 1.64      |\n",
      "|    total_reward       | -4.1      |\n",
      "|    total_reward_pct   | -0.0041   |\n",
      "|    total_trades       | 34        |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.4      |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -7.42e-06 |\n",
      "|    std                | 2.66      |\n",
      "|    value_loss         | 2.51e-11  |\n",
      "-------------------------------------\n",
      "day: 95, episode: 3370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.76\n",
      "total_reward: -11.24\n",
      "total_cost: 2.24\n",
      "total_trades: 37\n",
      "Sharpe: -2.558\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.98     |\n",
      "|    total_reward       | -13.3    |\n",
      "|    total_reward_pct   | -0.0133  |\n",
      "|    total_trades       | 35       |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.41    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 3.37e-05 |\n",
      "|    std                | 2.68     |\n",
      "|    value_loss         | 2.88e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+05    |\n",
      "|    total_cost         | 1.68     |\n",
      "|    total_reward       | -5.94    |\n",
      "|    total_reward_pct   | -0.00594 |\n",
      "|    total_trades       | 30       |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -3.1e-08 |\n",
      "|    std                | 2.71     |\n",
      "|    value_loss         | 2.07e-15 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9upN8FI2r_X1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUFJlHsi-Ka-",
    "outputId": "c669cd1c-19c3-4851-9fbf-fe41813eb4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5J_Scwp-Nis",
    "outputId": "5c6b156e-7c34-49ec-d00d-ec92457bf141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg/ddpg_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 108       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total timesteps  | 384       |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.17e+03 |\n",
      "|    critic_loss      | 1.61e+04  |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    n_updates        | 192       |\n",
      "-----------------------------------\n",
      "day: 95, episode: 530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 76        |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 768       |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.13e+03 |\n",
      "|    critic_loss      | 1.55e+04  |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    n_updates        | 576       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 70        |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total timesteps  | 1152      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.08e+03 |\n",
      "|    critic_loss      | 1.94e+04  |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    n_updates        | 960       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 67        |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total timesteps  | 1536      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.05e+03 |\n",
      "|    critic_loss      | 1.28e+04  |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    n_updates        | 1344      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 540\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 65        |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total timesteps  | 1920      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.01e+03 |\n",
      "|    critic_loss      | 1.52e+04  |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    n_updates        | 1728      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total timesteps  | 2304     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -968     |\n",
      "|    critic_loss      | 1.41e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 2112     |\n",
      "----------------------------------\n",
      "day: 95, episode: 550\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total timesteps  | 2688     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -930     |\n",
      "|    critic_loss      | 1.47e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 2496     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total timesteps  | 3072     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -893     |\n",
      "|    critic_loss      | 1.31e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 2880     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total timesteps  | 3456     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -856     |\n",
      "|    critic_loss      | 1.27e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 3264     |\n",
      "----------------------------------\n",
      "day: 95, episode: 560\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total timesteps  | 3840     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -825     |\n",
      "|    critic_loss      | 1.26e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 3648     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total timesteps  | 4224     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -795     |\n",
      "|    critic_loss      | 7.14e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 4032     |\n",
      "----------------------------------\n",
      "day: 95, episode: 570\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total timesteps  | 4608     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -761     |\n",
      "|    critic_loss      | 1.04e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 4416     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total timesteps  | 4992     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -731     |\n",
      "|    critic_loss      | 1.16e+04 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 4800     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total timesteps  | 5376     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -704     |\n",
      "|    critic_loss      | 7.49e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 5184     |\n",
      "----------------------------------\n",
      "day: 95, episode: 580\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total timesteps  | 5760     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -676     |\n",
      "|    critic_loss      | 7.59e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 5568     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total timesteps  | 6144     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -649     |\n",
      "|    critic_loss      | 9.83e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 5952     |\n",
      "----------------------------------\n",
      "day: 95, episode: 590\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total timesteps  | 6528     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -626     |\n",
      "|    critic_loss      | 6.48e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 6336     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 6912     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -604     |\n",
      "|    critic_loss      | 5.85e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 6720     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total timesteps  | 7296     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -577     |\n",
      "|    critic_loss      | 8.84e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 7104     |\n",
      "----------------------------------\n",
      "day: 95, episode: 600\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total timesteps  | 7680     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -556     |\n",
      "|    critic_loss      | 5.49e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 7488     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 8064     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -537     |\n",
      "|    critic_loss      | 5.03e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 7872     |\n",
      "----------------------------------\n",
      "day: 95, episode: 610\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total timesteps  | 8448     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -514     |\n",
      "|    critic_loss      | 8.41e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 8256     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 8832     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -495     |\n",
      "|    critic_loss      | 7.33e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 8640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total timesteps  | 9216     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -477     |\n",
      "|    critic_loss      | 4.71e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 9024     |\n",
      "----------------------------------\n",
      "day: 95, episode: 620\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -459     |\n",
      "|    critic_loss      | 3.87e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 9408     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total timesteps  | 9984     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -440     |\n",
      "|    critic_loss      | 3.82e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 9792     |\n",
      "----------------------------------\n",
      "day: 95, episode: 630\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total timesteps  | 10368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -424     |\n",
      "|    critic_loss      | 3.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 10176    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 10752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -408     |\n",
      "|    critic_loss      | 3.97e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 10560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total timesteps  | 11136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -391     |\n",
      "|    critic_loss      | 3.87e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 10944    |\n",
      "----------------------------------\n",
      "day: 95, episode: 640\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total timesteps  | 11520    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -377     |\n",
      "|    critic_loss      | 3.18e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 11328    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total timesteps  | 11904    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -363     |\n",
      "|    critic_loss      | 3.21e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 11712    |\n",
      "----------------------------------\n",
      "day: 95, episode: 650\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total timesteps  | 12288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -349     |\n",
      "|    critic_loss      | 2.55e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 12096    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total timesteps  | 12672    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -336     |\n",
      "|    critic_loss      | 2.53e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 12480    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 13056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -321     |\n",
      "|    critic_loss      | 4.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 12864    |\n",
      "----------------------------------\n",
      "day: 95, episode: 660\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total timesteps  | 13440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -308     |\n",
      "|    critic_loss      | 4.18e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 13248    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total timesteps  | 13824    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -295     |\n",
      "|    critic_loss      | 5.73e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 13632    |\n",
      "----------------------------------\n",
      "day: 95, episode: 670\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 14208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -285     |\n",
      "|    critic_loss      | 3.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 14016    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total timesteps  | 14592    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -273     |\n",
      "|    critic_loss      | 2.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 14400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total timesteps  | 14976    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -263     |\n",
      "|    critic_loss      | 3.7e+03  |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 14784    |\n",
      "----------------------------------\n",
      "day: 95, episode: 680\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total timesteps  | 15360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -253     |\n",
      "|    critic_loss      | 2.06e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 15168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total timesteps  | 15744    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -242     |\n",
      "|    critic_loss      | 3.03e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 15552    |\n",
      "----------------------------------\n",
      "day: 95, episode: 690\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total timesteps  | 16128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -232     |\n",
      "|    critic_loss      | 2.18e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 15936    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total timesteps  | 16512    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -223     |\n",
      "|    critic_loss      | 2.82e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 16320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total timesteps  | 16896    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -215     |\n",
      "|    critic_loss      | 3.55e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 16704    |\n",
      "----------------------------------\n",
      "day: 95, episode: 700\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total timesteps  | 17280    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -207     |\n",
      "|    critic_loss      | 2.94e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 17088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total timesteps  | 17664    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -198     |\n",
      "|    critic_loss      | 4.01e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 17472    |\n",
      "----------------------------------\n",
      "day: 95, episode: 710\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total timesteps  | 18048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -191     |\n",
      "|    critic_loss      | 2.23e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 17856    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total timesteps  | 18432    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -184     |\n",
      "|    critic_loss      | 3.08e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 18240    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total timesteps  | 18816    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -177     |\n",
      "|    critic_loss      | 659      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 18624    |\n",
      "----------------------------------\n",
      "day: 95, episode: 720\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -170     |\n",
      "|    critic_loss      | 1.41e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 19008    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total timesteps  | 19584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -162     |\n",
      "|    critic_loss      | 2.64e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 19392    |\n",
      "----------------------------------\n",
      "day: 95, episode: 730\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total timesteps  | 19968    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -157     |\n",
      "|    critic_loss      | 2.18e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 19776    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total timesteps  | 20352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -150     |\n",
      "|    critic_loss      | 3.07e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 20160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total timesteps  | 20736    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -143     |\n",
      "|    critic_loss      | 1.19e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 20544    |\n",
      "----------------------------------\n",
      "day: 95, episode: 740\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total timesteps  | 21120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -138     |\n",
      "|    critic_loss      | 2.08e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 20928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total timesteps  | 21504    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -133     |\n",
      "|    critic_loss      | 2.38e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 21312    |\n",
      "----------------------------------\n",
      "day: 95, episode: 750\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total timesteps  | 21888    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -127     |\n",
      "|    critic_loss      | 1.01e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 21696    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 375      |\n",
      "|    total timesteps  | 22272    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -122     |\n",
      "|    critic_loss      | 1.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 22080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 382      |\n",
      "|    total timesteps  | 22656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -117     |\n",
      "|    critic_loss      | 1.9e+03  |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 22464    |\n",
      "----------------------------------\n",
      "day: 95, episode: 760\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total timesteps  | 23040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -113     |\n",
      "|    critic_loss      | 2.32e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 22848    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 395      |\n",
      "|    total timesteps  | 23424    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -108     |\n",
      "|    critic_loss      | 2.72e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 23232    |\n",
      "----------------------------------\n",
      "day: 95, episode: 770\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 401      |\n",
      "|    total timesteps  | 23808    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -104     |\n",
      "|    critic_loss      | 723      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 23616    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 408      |\n",
      "|    total timesteps  | 24192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -99.9    |\n",
      "|    critic_loss      | 1.56e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 24000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 414      |\n",
      "|    total timesteps  | 24576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -96.6    |\n",
      "|    critic_loss      | 1.39e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 24384    |\n",
      "----------------------------------\n",
      "day: 95, episode: 780\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 421      |\n",
      "|    total timesteps  | 24960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -93      |\n",
      "|    critic_loss      | 1.25e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 24768    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 427      |\n",
      "|    total timesteps  | 25344    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -89.2    |\n",
      "|    critic_loss      | 1.44e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 25152    |\n",
      "----------------------------------\n",
      "day: 95, episode: 790\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 434      |\n",
      "|    total timesteps  | 25728    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -84.8    |\n",
      "|    critic_loss      | 2.25e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 25536    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total timesteps  | 26112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -82.6    |\n",
      "|    critic_loss      | 1.16e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 25920    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 446      |\n",
      "|    total timesteps  | 26496    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -80.2    |\n",
      "|    critic_loss      | 1.53e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 26304    |\n",
      "----------------------------------\n",
      "day: 95, episode: 800\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 453      |\n",
      "|    total timesteps  | 26880    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -76.4    |\n",
      "|    critic_loss      | 1.65e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 26688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 459      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -74.4    |\n",
      "|    critic_loss      | 909      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 27072    |\n",
      "----------------------------------\n",
      "day: 95, episode: 810\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 466      |\n",
      "|    total timesteps  | 27648    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -71.6    |\n",
      "|    critic_loss      | 743      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 27456    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 472      |\n",
      "|    total timesteps  | 28032    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -68.7    |\n",
      "|    critic_loss      | 762      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 27840    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 479      |\n",
      "|    total timesteps  | 28416    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -66      |\n",
      "|    critic_loss      | 921      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 28224    |\n",
      "----------------------------------\n",
      "day: 95, episode: 820\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 485      |\n",
      "|    total timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -63.5    |\n",
      "|    critic_loss      | 1.49e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 28608    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 492      |\n",
      "|    total timesteps  | 29184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -60      |\n",
      "|    critic_loss      | 1.54e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 28992    |\n",
      "----------------------------------\n",
      "day: 95, episode: 830\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 498      |\n",
      "|    total timesteps  | 29568    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -59.1    |\n",
      "|    critic_loss      | 1.16e+03 |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 29376    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 504      |\n",
      "|    total timesteps  | 29952    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -56      |\n",
      "|    critic_loss      | 915      |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    n_updates        | 29760    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sve9WGvsC__"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjuycpS-Qvn",
    "outputId": "00ba85cf-c215-461e-e878-1590afe045eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9hCHA8A-RSy",
    "outputId": "a538d5f6-bd44-400e-e566-8c7f2305b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ppo/ppo_1\n",
      "day: 95, episode: 840\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99976.09\n",
      "total_reward: -23.91\n",
      "total_cost: 5.94\n",
      "total_trades: 95\n",
      "Sharpe: -2.486\n",
      "=================================\n",
      "day: 95, episode: 850\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99959.09\n",
      "total_reward: -40.91\n",
      "total_cost: 5.19\n",
      "total_trades: 87\n",
      "Sharpe: -2.285\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 4.07     |\n",
      "|    total_reward     | -17.6    |\n",
      "|    total_reward_pct | -0.0176  |\n",
      "|    total_trades     | 78       |\n",
      "| time/               |          |\n",
      "|    fps              | 664      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "day: 95, episode: 860\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99905.87\n",
      "total_reward: -94.13\n",
      "total_cost: 7.06\n",
      "total_trades: 95\n",
      "Sharpe: -2.290\n",
      "=================================\n",
      "day: 95, episode: 870\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99961.52\n",
      "total_reward: -38.48\n",
      "total_cost: 6.52\n",
      "total_trades: 94\n",
      "Sharpe: -3.110\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.99e+04     |\n",
      "|    total_cost           | 6.02         |\n",
      "|    total_reward         | -50.3        |\n",
      "|    total_reward_pct     | -0.0503      |\n",
      "|    total_trades         | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018597677 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -22.2        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0467       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.103        |\n",
      "------------------------------------------\n",
      "day: 95, episode: 880\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99968.84\n",
      "total_reward: -31.16\n",
      "total_cost: 5.84\n",
      "total_trades: 87\n",
      "Sharpe: -1.819\n",
      "=================================\n",
      "day: 95, episode: 890\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99973.93\n",
      "total_reward: -26.07\n",
      "total_cost: 5.96\n",
      "total_trades: 92\n",
      "Sharpe: -3.081\n",
      "=================================\n",
      "day: 95, episode: 900\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99941.47\n",
      "total_reward: -58.53\n",
      "total_cost: 6.64\n",
      "total_trades: 92\n",
      "Sharpe: -2.460\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.99e+04     |\n",
      "|    total_cost           | 6.64         |\n",
      "|    total_reward         | -58.5        |\n",
      "|    total_reward_pct     | -0.0585      |\n",
      "|    total_trades         | 92           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 576          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001741648 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -8.31e+11    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0162       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -4.62e-05    |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.0531       |\n",
      "------------------------------------------\n",
      "day: 95, episode: 910\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99979.16\n",
      "total_reward: -20.84\n",
      "total_cost: 6.25\n",
      "total_trades: 92\n",
      "Sharpe: -1.911\n",
      "=================================\n",
      "day: 95, episode: 920\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99947.07\n",
      "total_reward: -52.93\n",
      "total_cost: 6.83\n",
      "total_trades: 91\n",
      "Sharpe: -2.686\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+05      |\n",
      "|    total_cost           | 5.45       |\n",
      "|    total_reward         | -19.4      |\n",
      "|    total_reward_pct     | -0.0194    |\n",
      "|    total_trades         | 88         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00422058 |\n",
      "|    clip_fraction        | 0.00337    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00489    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.000627  |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 0.0273     |\n",
      "----------------------------------------\n",
      "day: 95, episode: 930\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99956.34\n",
      "total_reward: -43.66\n",
      "total_cost: 6.31\n",
      "total_trades: 87\n",
      "Sharpe: -2.732\n",
      "=================================\n",
      "day: 95, episode: 940\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99974.10\n",
      "total_reward: -25.90\n",
      "total_cost: 6.30\n",
      "total_trades: 92\n",
      "Sharpe: -2.135\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 9.99e+04       |\n",
      "|    total_cost           | 6.42           |\n",
      "|    total_reward         | -59.2          |\n",
      "|    total_reward_pct     | -0.0592        |\n",
      "|    total_trades         | 93             |\n",
      "| time/                   |                |\n",
      "|    fps                  | 563            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 18             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00015341115 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.4           |\n",
      "|    explained_variance   | nan            |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | -0.00157       |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -7.24e-05      |\n",
      "|    std                  | 0.982          |\n",
      "|    value_loss           | 0.0125         |\n",
      "--------------------------------------------\n",
      "day: 95, episode: 950\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99969.25\n",
      "total_reward: -30.75\n",
      "total_cost: 6.31\n",
      "total_trades: 92\n",
      "Sharpe: -3.518\n",
      "=================================\n",
      "day: 95, episode: 960\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99972.81\n",
      "total_reward: -27.19\n",
      "total_cost: 6.42\n",
      "total_trades: 90\n",
      "Sharpe: -2.623\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 6.04         |\n",
      "|    total_reward         | -33.9        |\n",
      "|    total_reward_pct     | -0.0339      |\n",
      "|    total_trades         | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043742936 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.51e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0121      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 0.00574      |\n",
      "------------------------------------------\n",
      "day: 95, episode: 970\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99984.10\n",
      "total_reward: -15.90\n",
      "total_cost: 4.61\n",
      "total_trades: 81\n",
      "Sharpe: -3.142\n",
      "=================================\n",
      "day: 95, episode: 980\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99976.31\n",
      "total_reward: -23.69\n",
      "total_cost: 4.54\n",
      "total_trades: 76\n",
      "Sharpe: -3.038\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+05      |\n",
      "|    total_cost           | 3.49       |\n",
      "|    total_reward         | -7.17      |\n",
      "|    total_reward_pct     | -0.00717   |\n",
      "|    total_trades         | 75         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 558        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00051335 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.4       |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00605   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.000103  |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 0.00277    |\n",
      "----------------------------------------\n",
      "day: 95, episode: 990\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99960.73\n",
      "total_reward: -39.27\n",
      "total_cost: 6.43\n",
      "total_trades: 92\n",
      "Sharpe: -2.109\n",
      "=================================\n",
      "day: 95, episode: 1000\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.57\n",
      "total_reward: -11.43\n",
      "total_cost: 5.14\n",
      "total_trades: 86\n",
      "Sharpe: -1.857\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.99e+04     |\n",
      "|    total_cost           | 7.12         |\n",
      "|    total_reward         | -52          |\n",
      "|    total_reward_pct     | -0.052       |\n",
      "|    total_trades         | 94           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.588777e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00634     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 7.27e-05     |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 0.0013       |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1010\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99971.19\n",
      "total_reward: -28.81\n",
      "total_cost: 5.99\n",
      "total_trades: 91\n",
      "Sharpe: -2.541\n",
      "=================================\n",
      "day: 95, episode: 1020\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99963.61\n",
      "total_reward: -36.39\n",
      "total_cost: 6.80\n",
      "total_trades: 93\n",
      "Sharpe: -2.344\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 4.78         |\n",
      "|    total_reward         | -15.2        |\n",
      "|    total_reward_pct     | -0.0152      |\n",
      "|    total_trades         | 77           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026266663 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.19e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000606    |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 0.000639     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1030\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99985.99\n",
      "total_reward: -14.01\n",
      "total_cost: 4.82\n",
      "total_trades: 80\n",
      "Sharpe: -3.469\n",
      "=================================\n",
      "day: 95, episode: 1040\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99989.66\n",
      "total_reward: -10.34\n",
      "total_cost: 4.18\n",
      "total_trades: 81\n",
      "Sharpe: -3.907\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 6.7         |\n",
      "|    total_reward         | -43.6       |\n",
      "|    total_reward_pct     | -0.0436     |\n",
      "|    total_trades         | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002081789 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -5.04e+12   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00083    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000217   |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.000305    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1050\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99975.02\n",
      "total_reward: -24.98\n",
      "total_cost: 6.21\n",
      "total_trades: 90\n",
      "Sharpe: -3.068\n",
      "=================================\n",
      "day: 95, episode: 1060\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.20\n",
      "total_reward: -7.80\n",
      "total_cost: 3.72\n",
      "total_trades: 78\n",
      "Sharpe: -4.010\n",
      "=================================\n",
      "day: 95, episode: 1070\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99969.76\n",
      "total_reward: -30.24\n",
      "total_cost: 4.92\n",
      "total_trades: 83\n",
      "Sharpe: -3.224\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 4.92         |\n",
      "|    total_reward         | -30.2        |\n",
      "|    total_reward_pct     | -0.0302      |\n",
      "|    total_trades         | 83           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056655332 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.08e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00829     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000624    |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.000145     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1080\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99975.02\n",
      "total_reward: -24.98\n",
      "total_cost: 4.61\n",
      "total_trades: 79\n",
      "Sharpe: -3.386\n",
      "=================================\n",
      "day: 95, episode: 1090\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99969.34\n",
      "total_reward: -30.66\n",
      "total_cost: 5.28\n",
      "total_trades: 93\n",
      "Sharpe: -3.838\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 5.58         |\n",
      "|    total_reward         | -10.9        |\n",
      "|    total_reward_pct     | -0.0109      |\n",
      "|    total_trades         | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037694066 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -1.2e+12     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00164     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000146    |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 7.25e-05     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99991.02\n",
      "total_reward: -8.98\n",
      "total_cost: 4.13\n",
      "total_trades: 71\n",
      "Sharpe: -4.842\n",
      "=================================\n",
      "day: 95, episode: 1110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99985.71\n",
      "total_reward: -14.29\n",
      "total_cost: 4.77\n",
      "total_trades: 84\n",
      "Sharpe: -2.459\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 1e+05          |\n",
      "|    total_cost           | 4.36           |\n",
      "|    total_reward         | -26.9          |\n",
      "|    total_reward_pct     | -0.0269        |\n",
      "|    total_trades         | 82             |\n",
      "| time/                   |                |\n",
      "|    fps                  | 552            |\n",
      "|    iterations           | 13             |\n",
      "|    time_elapsed         | 48             |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.6669819e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.4           |\n",
      "|    explained_variance   | -9.89e+12      |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | -0.00703       |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | 0.000131       |\n",
      "|    std                  | 0.977          |\n",
      "|    value_loss           | 3.67e-05       |\n",
      "--------------------------------------------\n",
      "day: 95, episode: 1120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99987.96\n",
      "total_reward: -12.04\n",
      "total_cost: 3.74\n",
      "total_trades: 68\n",
      "Sharpe: -3.097\n",
      "=================================\n",
      "day: 95, episode: 1130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.82\n",
      "total_reward: -7.18\n",
      "total_cost: 3.12\n",
      "total_trades: 74\n",
      "Sharpe: -3.589\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 4.27        |\n",
      "|    total_reward         | -19.3       |\n",
      "|    total_reward_pct     | -0.0193     |\n",
      "|    total_trades         | 77          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003337428 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0163     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000863   |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.52\n",
      "total_reward: -1.48\n",
      "total_cost: 2.69\n",
      "total_trades: 72\n",
      "Sharpe: -0.632\n",
      "=================================\n",
      "day: 95, episode: 1150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99987.69\n",
      "total_reward: -12.31\n",
      "total_cost: 2.76\n",
      "total_trades: 61\n",
      "Sharpe: -2.808\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 2.63          |\n",
      "|    total_reward         | -7.46         |\n",
      "|    total_reward_pct     | -0.00746      |\n",
      "|    total_trades         | 67            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 551           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 55            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0005038413 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -9.72e+12     |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00525      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | 8.53e-05      |\n",
      "|    std                  | 0.974         |\n",
      "|    value_loss           | 9.26e-06      |\n",
      "-------------------------------------------\n",
      "day: 95, episode: 1160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99985.86\n",
      "total_reward: -14.14\n",
      "total_cost: 5.09\n",
      "total_trades: 88\n",
      "Sharpe: -3.039\n",
      "=================================\n",
      "day: 95, episode: 1170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99966.04\n",
      "total_reward: -33.96\n",
      "total_cost: 2.95\n",
      "total_trades: 68\n",
      "Sharpe: -2.222\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 3.59         |\n",
      "|    total_reward         | -10.5        |\n",
      "|    total_reward_pct     | -0.0105      |\n",
      "|    total_trades         | 72           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029460597 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0189      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 4.85e-06     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99988.38\n",
      "total_reward: -11.62\n",
      "total_cost: 4.06\n",
      "total_trades: 77\n",
      "Sharpe: -3.213\n",
      "=================================\n",
      "day: 95, episode: 1190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99973.79\n",
      "total_reward: -26.21\n",
      "total_cost: 3.58\n",
      "total_trades: 82\n",
      "Sharpe: -3.590\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 2.54         |\n",
      "|    total_reward         | -3.78        |\n",
      "|    total_reward_pct     | -0.00378     |\n",
      "|    total_trades         | 65           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023583206 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -1.18e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000811    |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 2.43e-06     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99986.77\n",
      "total_reward: -13.23\n",
      "total_cost: 3.70\n",
      "total_trades: 67\n",
      "Sharpe: -3.481\n",
      "=================================\n",
      "day: 95, episode: 1210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.52\n",
      "total_reward: -7.48\n",
      "total_cost: 2.62\n",
      "total_trades: 60\n",
      "Sharpe: -5.133\n",
      "=================================\n",
      "day: 95, episode: 1220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99991.12\n",
      "total_reward: -8.88\n",
      "total_cost: 2.74\n",
      "total_trades: 63\n",
      "Sharpe: -3.260\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 2.74         |\n",
      "|    total_reward         | -8.88        |\n",
      "|    total_reward_pct     | -0.00888     |\n",
      "|    total_trades         | 63           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048893923 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -5.13e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0123      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.17e-06     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99995.20\n",
      "total_reward: -4.80\n",
      "total_cost: 1.40\n",
      "total_trades: 45\n",
      "Sharpe: -4.916\n",
      "=================================\n",
      "day: 95, episode: 1240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99996.75\n",
      "total_reward: -3.25\n",
      "total_cost: 2.59\n",
      "total_trades: 67\n",
      "Sharpe: -2.646\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 2.01         |\n",
      "|    total_reward         | -4.14        |\n",
      "|    total_reward_pct     | -0.00414     |\n",
      "|    total_trades         | 48           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012286699 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -2.24e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000265    |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 5.29e-07     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99995.18\n",
      "total_reward: -4.82\n",
      "total_cost: 2.32\n",
      "total_trades: 56\n",
      "Sharpe: -2.260\n",
      "=================================\n",
      "day: 95, episode: 1260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.33\n",
      "total_reward: -7.67\n",
      "total_cost: 2.39\n",
      "total_trades: 59\n",
      "Sharpe: -3.407\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 1e+05          |\n",
      "|    total_cost           | 2.29           |\n",
      "|    total_reward         | -8.45          |\n",
      "|    total_reward_pct     | -0.00845       |\n",
      "|    total_trades         | 60             |\n",
      "| time/                   |                |\n",
      "|    fps                  | 551            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 74             |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00018270142 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.38          |\n",
      "|    explained_variance   | nan            |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | -0.00257       |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.000276      |\n",
      "|    std                  | 0.952          |\n",
      "|    value_loss           | 3e-07          |\n",
      "--------------------------------------------\n",
      "day: 95, episode: 1270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.97\n",
      "total_reward: -5.03\n",
      "total_cost: 1.23\n",
      "total_trades: 40\n",
      "Sharpe: -2.775\n",
      "=================================\n",
      "day: 95, episode: 1280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99993.20\n",
      "total_reward: -6.80\n",
      "total_cost: 1.95\n",
      "total_trades: 55\n",
      "Sharpe: -2.885\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 2.54         |\n",
      "|    total_reward         | -6.84        |\n",
      "|    total_reward_pct     | -0.00684     |\n",
      "|    total_trades         | 57           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057166344 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0123      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.77e-07     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.35\n",
      "total_reward: -7.65\n",
      "total_cost: 1.78\n",
      "total_trades: 48\n",
      "Sharpe: -2.718\n",
      "=================================\n",
      "day: 95, episode: 1300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.21\n",
      "total_reward: -1.79\n",
      "total_cost: 0.91\n",
      "total_trades: 41\n",
      "Sharpe: -6.416\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 1.67         |\n",
      "|    total_reward         | -3.17        |\n",
      "|    total_reward_pct     | -0.00317     |\n",
      "|    total_trades         | 46           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034110933 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -1.83e+12    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0132      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.05e-07     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.41\n",
      "total_reward: -5.59\n",
      "total_cost: 1.51\n",
      "total_trades: 55\n",
      "Sharpe: -3.218\n",
      "=================================\n",
      "day: 95, episode: 1320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99994.92\n",
      "total_reward: -5.08\n",
      "total_cost: 1.95\n",
      "total_trades: 50\n",
      "Sharpe: -4.223\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 1.17        |\n",
      "|    total_reward         | -2.67       |\n",
      "|    total_reward_pct     | -0.00267    |\n",
      "|    total_trades         | 38          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006719809 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -1.16e+12   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00302    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 6.6e-08     |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.60\n",
      "total_reward: -1.40\n",
      "total_cost: 0.72\n",
      "total_trades: 29\n",
      "Sharpe: -3.642\n",
      "=================================\n",
      "day: 95, episode: 1340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99992.86\n",
      "total_reward: -7.14\n",
      "total_cost: 1.78\n",
      "total_trades: 49\n",
      "Sharpe: -2.948\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+05      |\n",
      "|    total_cost           | 0.476      |\n",
      "|    total_reward         | -1.06      |\n",
      "|    total_reward_pct     | -0.00106   |\n",
      "|    total_trades         | 21         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 551        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00423476 |\n",
      "|    clip_fraction        | 0.0323     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0165    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00265   |\n",
      "|    std                  | 0.942      |\n",
      "|    value_loss           | 3.45e-08   |\n",
      "----------------------------------------\n",
      "day: 95, episode: 1350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.58\n",
      "total_reward: -2.42\n",
      "total_cost: 0.73\n",
      "total_trades: 27\n",
      "Sharpe: -3.336\n",
      "=================================\n",
      "day: 95, episode: 1360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.53\n",
      "total_reward: -0.47\n",
      "total_cost: 0.58\n",
      "total_trades: 27\n",
      "Sharpe: -0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 1.15        |\n",
      "|    total_reward         | -0.131      |\n",
      "|    total_reward_pct     | -0.000131   |\n",
      "|    total_trades         | 32          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010400049 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 3.12e-08    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.64\n",
      "total_reward: 0.64\n",
      "total_cost: 0.71\n",
      "total_trades: 28\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "day: 95, episode: 1380\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.83\n",
      "total_reward: -1.17\n",
      "total_cost: 0.55\n",
      "total_trades: 26\n",
      "Sharpe: -4.570\n",
      "=================================\n",
      "day: 95, episode: 1390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.17\n",
      "total_reward: -2.83\n",
      "total_cost: 0.98\n",
      "total_trades: 34\n",
      "Sharpe: -2.202\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.984        |\n",
      "|    total_reward         | -2.83        |\n",
      "|    total_reward_pct     | -0.00283     |\n",
      "|    total_trades         | 34           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020846785 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00845     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 1.77e-08     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1400\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.80\n",
      "total_reward: -2.20\n",
      "total_cost: 0.59\n",
      "total_trades: 29\n",
      "Sharpe: -3.421\n",
      "=================================\n",
      "day: 95, episode: 1410\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.00\n",
      "total_reward: -1.00\n",
      "total_cost: 0.90\n",
      "total_trades: 26\n",
      "Sharpe: -2.855\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.531        |\n",
      "|    total_reward         | -0.406       |\n",
      "|    total_reward_pct     | -0.000406    |\n",
      "|    total_trades         | 17           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024183406 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0106      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000385    |\n",
      "|    std                  | 0.928        |\n",
      "|    value_loss           | 1.08e-08     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1420\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.41\n",
      "total_reward: -2.59\n",
      "total_cost: 0.82\n",
      "total_trades: 34\n",
      "Sharpe: -6.085\n",
      "=================================\n",
      "day: 95, episode: 1430\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.18\n",
      "total_reward: -1.82\n",
      "total_cost: 0.89\n",
      "total_trades: 37\n",
      "Sharpe: -7.295\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.996        |\n",
      "|    total_reward         | -4.01        |\n",
      "|    total_reward_pct     | -0.00401     |\n",
      "|    total_trades         | 28           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038041172 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0086      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 6.73e-09     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1440\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.50\n",
      "total_reward: -1.50\n",
      "total_cost: 0.53\n",
      "total_trades: 21\n",
      "Sharpe: -3.413\n",
      "=================================\n",
      "day: 95, episode: 1450\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.58\n",
      "total_reward: -1.42\n",
      "total_cost: 0.66\n",
      "total_trades: 22\n",
      "Sharpe: -5.829\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.333        |\n",
      "|    total_reward         | -0.736       |\n",
      "|    total_reward_pct     | -0.000736    |\n",
      "|    total_trades         | 15           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047127856 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0191      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    std                  | 0.913        |\n",
      "|    value_loss           | 4.62e-09     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1460\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.07\n",
      "total_reward: -0.93\n",
      "total_cost: 0.50\n",
      "total_trades: 25\n",
      "Sharpe: -4.974\n",
      "=================================\n",
      "day: 95, episode: 1470\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.21\n",
      "total_reward: 0.21\n",
      "total_cost: 0.55\n",
      "total_trades: 18\n",
      "Sharpe: 0.346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0.39        |\n",
      "|    total_reward         | -1.34       |\n",
      "|    total_reward_pct     | -0.00134    |\n",
      "|    total_trades         | 18          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002827107 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0189     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 2.24e-09    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1480\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99998.97\n",
      "total_reward: -1.03\n",
      "total_cost: 0.50\n",
      "total_trades: 13\n",
      "Sharpe: -5.789\n",
      "=================================\n",
      "day: 95, episode: 1490\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99997.54\n",
      "total_reward: -2.46\n",
      "total_cost: 0.58\n",
      "total_trades: 16\n",
      "Sharpe: -2.881\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.247        |\n",
      "|    total_reward         | -0.481       |\n",
      "|    total_reward_pct     | -0.000481    |\n",
      "|    total_trades         | 13           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064605344 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00502     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 2.2e-09      |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1500\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.29\n",
      "total_reward: 0.29\n",
      "total_cost: 0.12\n",
      "total_trades: 6\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "day: 95, episode: 1510\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.83\n",
      "total_reward: -0.17\n",
      "total_cost: 0.09\n",
      "total_trades: 4\n",
      "Sharpe: -3.079\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.189        |\n",
      "|    total_reward         | -0.293       |\n",
      "|    total_reward_pct     | -0.000293    |\n",
      "|    total_trades         | 11           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033582607 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00259     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 1.42e-09     |\n",
      "------------------------------------------\n",
      "day: 95, episode: 1520\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.80\n",
      "total_reward: -0.20\n",
      "total_cost: 0.10\n",
      "total_trades: 8\n",
      "Sharpe: -3.012\n",
      "=================================\n",
      "day: 95, episode: 1530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.60\n",
      "total_reward: -0.40\n",
      "total_cost: 0.15\n",
      "total_trades: 6\n",
      "Sharpe: -2.984\n",
      "=================================\n",
      "day: 95, episode: 1540\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.81\n",
      "total_reward: -0.19\n",
      "total_cost: 0.21\n",
      "total_trades: 10\n",
      "Sharpe: -2.087\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+05      |\n",
      "|    total_cost           | 0.21       |\n",
      "|    total_reward         | -0.191     |\n",
      "|    total_reward_pct     | -0.000191  |\n",
      "|    total_trades         | 10         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 549        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 122        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00434699 |\n",
      "|    clip_fraction        | 0.0142     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0168    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00214   |\n",
      "|    std                  | 0.89       |\n",
      "|    value_loss           | 1.02e-09   |\n",
      "----------------------------------------\n",
      "day: 95, episode: 1550\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.14\n",
      "total_reward: -0.86\n",
      "total_cost: 0.18\n",
      "total_trades: 5\n",
      "Sharpe: -2.160\n",
      "=================================\n",
      "day: 95, episode: 1560\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.95\n",
      "total_reward: -0.05\n",
      "total_cost: 0.04\n",
      "total_trades: 6\n",
      "Sharpe: -2.474\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 0.157         |\n",
      "|    total_reward         | -0.272        |\n",
      "|    total_reward_pct     | -0.000272     |\n",
      "|    total_trades         | 6             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 549           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 126           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0001876431 |\n",
      "|    clip_fraction        | 0.0113        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00735      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.00273      |\n",
      "|    std                  | 0.882         |\n",
      "|    value_loss           | 2.28e-10      |\n",
      "-------------------------------------------\n",
      "day: 95, episode: 1570\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.83\n",
      "total_reward: -0.17\n",
      "total_cost: 0.08\n",
      "total_trades: 6\n",
      "Sharpe: -3.297\n",
      "=================================\n",
      "day: 95, episode: 1580\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0.278       |\n",
      "|    total_reward         | -0.596      |\n",
      "|    total_reward_pct     | -0.000596   |\n",
      "|    total_trades         | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004608955 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00139    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 4.65e-10    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1590\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.93\n",
      "total_reward: -0.07\n",
      "total_cost: 0.05\n",
      "total_trades: 2\n",
      "Sharpe: -2.015\n",
      "=================================\n",
      "day: 95, episode: 1600\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.78\n",
      "total_reward: -0.22\n",
      "total_cost: 0.09\n",
      "total_trades: 10\n",
      "Sharpe: -4.846\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 0.0697        |\n",
      "|    total_reward         | -0.147        |\n",
      "|    total_reward_pct     | -0.000147     |\n",
      "|    total_trades         | 6             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 548           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 134           |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093996205 |\n",
      "|    clip_fraction        | 0.018         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.28         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00417      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.00322      |\n",
      "|    std                  | 0.872         |\n",
      "|    value_loss           | 1.1e-10       |\n",
      "-------------------------------------------\n",
      "day: 95, episode: 1610\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.87\n",
      "total_reward: -0.13\n",
      "total_cost: 0.05\n",
      "total_trades: 2\n",
      "Sharpe: -2.274\n",
      "=================================\n",
      "day: 95, episode: 1620\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 0.0422        |\n",
      "|    total_reward         | -0.05         |\n",
      "|    total_reward_pct     | -5e-05        |\n",
      "|    total_trades         | 2             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 547           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056804926 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.27         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00859      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.0008       |\n",
      "|    std                  | 0.86          |\n",
      "|    value_loss           | 2.78e-10      |\n",
      "-------------------------------------------\n",
      "day: 95, episode: 1630\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.45\n",
      "total_reward: -0.55\n",
      "total_cost: 0.10\n",
      "total_trades: 4\n",
      "Sharpe: -1.716\n",
      "=================================\n",
      "day: 95, episode: 1640\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.97\n",
      "total_reward: -0.03\n",
      "total_cost: 0.02\n",
      "total_trades: 2\n",
      "Sharpe: -2.275\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 0           |\n",
      "|    total_reward_pct     | 0           |\n",
      "|    total_trades         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002477115 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 1.85e-10    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1650\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.98\n",
      "total_reward: -0.02\n",
      "total_cost: 0.12\n",
      "total_trades: 9\n",
      "Sharpe: -0.168\n",
      "=================================\n",
      "day: 95, episode: 1660\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.90\n",
      "total_reward: -0.10\n",
      "total_cost: 0.04\n",
      "total_trades: 2\n",
      "Sharpe: -2.293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0.152       |\n",
      "|    total_reward         | -0.339      |\n",
      "|    total_reward_pct     | -0.000339   |\n",
      "|    total_trades         | 4           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005646224 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00841    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 8.29e-11    |\n",
      "-----------------------------------------\n",
      "day: 95, episode: 1670\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99999.97\n",
      "total_reward: -0.03\n",
      "total_cost: 0.01\n",
      "total_trades: 2\n",
      "Sharpe: -2.300\n",
      "=================================\n",
      "day: 95, episode: 1680\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0.0424       |\n",
      "|    total_reward         | -0.0884      |\n",
      "|    total_reward_pct     | -8.84e-05    |\n",
      "|    total_trades         | 6            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029767775 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00694     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 3.17e-10     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiBG2ZknsG73"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcRdoBc8-Xze",
    "outputId": "2b3e89d2-e03e-42a9-d210-a45707c33ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 128, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.0003}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB5cAAio-ZSs",
    "outputId": "6da6c1b6-3fed-4051-95d9-a39338c0f472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/td3/td3_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 94       |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total timesteps  | 384      |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.57e+03 |\n",
      "|    critic_loss      | 2.97e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 192      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total timesteps  | 768      |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.51e+03 |\n",
      "|    critic_loss      | 2.73e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 576      |\n",
      "----------------------------------\n",
      "day: 95, episode: 1700\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 59       |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total timesteps  | 1152     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.44e+03 |\n",
      "|    critic_loss      | 2.53e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 960      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 56       |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total timesteps  | 1536     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.37e+03 |\n",
      "|    critic_loss      | 2.5e+05  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 1344     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1710\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total timesteps  | 1920     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.3e+03  |\n",
      "|    critic_loss      | 2.6e+05  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 1728     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total timesteps  | 2304     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.24e+03 |\n",
      "|    critic_loss      | 2.88e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 2112     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total timesteps  | 2688     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.17e+03 |\n",
      "|    critic_loss      | 2.55e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 2496     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1720\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total timesteps  | 3072     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.09e+03 |\n",
      "|    critic_loss      | 2.49e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 2880     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 52       |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total timesteps  | 3456     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 3.03e+03 |\n",
      "|    critic_loss      | 2.14e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 3264     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1730\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total timesteps  | 3840     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.98e+03 |\n",
      "|    critic_loss      | 2.28e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 3648     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total timesteps  | 4224     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.92e+03 |\n",
      "|    critic_loss      | 1.96e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 4032     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total timesteps  | 4608     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.86e+03 |\n",
      "|    critic_loss      | 1.83e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 4416     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1740\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total timesteps  | 4992     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.81e+03 |\n",
      "|    critic_loss      | 1.9e+05  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 4800     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 5376     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.76e+03 |\n",
      "|    critic_loss      | 1.75e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 5184     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1750\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 51       |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total timesteps  | 5760     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.7e+03  |\n",
      "|    critic_loss      | 1.87e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 5568     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total timesteps  | 6144     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.65e+03 |\n",
      "|    critic_loss      | 1.88e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 5952     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total timesteps  | 6528     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.6e+03  |\n",
      "|    critic_loss      | 1.6e+05  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 6336     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1760\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total timesteps  | 6912     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.56e+03 |\n",
      "|    critic_loss      | 1.52e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 6720     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 7296     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.52e+03 |\n",
      "|    critic_loss      | 1.48e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 7104     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1770\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total timesteps  | 7680     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.47e+03 |\n",
      "|    critic_loss      | 1.29e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 7488     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total timesteps  | 8064     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.43e+03 |\n",
      "|    critic_loss      | 1.34e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 7872     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total timesteps  | 8448     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.39e+03 |\n",
      "|    critic_loss      | 1.34e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 8256     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1780\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total timesteps  | 8832     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.35e+03 |\n",
      "|    critic_loss      | 1.27e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 8640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total timesteps  | 9216     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.31e+03 |\n",
      "|    critic_loss      | 1.14e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 9024     |\n",
      "----------------------------------\n",
      "day: 95, episode: 1790\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.27e+03 |\n",
      "|    critic_loss      | 1.24e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 9408     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total timesteps  | 9984     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.24e+03 |\n",
      "|    critic_loss      | 1.02e+05 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 9792     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total timesteps  | 10368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.19e+03 |\n",
      "|    critic_loss      | 1.1e+05  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 10176    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1800\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total timesteps  | 10752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.16e+03 |\n",
      "|    critic_loss      | 9.11e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 10560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total timesteps  | 11136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.12e+03 |\n",
      "|    critic_loss      | 9.13e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 10944    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1810\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total timesteps  | 11520    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.09e+03 |\n",
      "|    critic_loss      | 9.44e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 11328    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total timesteps  | 11904    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.06e+03 |\n",
      "|    critic_loss      | 8.77e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 11712    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total timesteps  | 12288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 2.02e+03 |\n",
      "|    critic_loss      | 9.28e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 12096    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1820\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 12672    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.98e+03 |\n",
      "|    critic_loss      | 9.64e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 12480    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total timesteps  | 13056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.95e+03 |\n",
      "|    critic_loss      | 8.71e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 12864    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1830\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 13440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.92e+03 |\n",
      "|    critic_loss      | 9.26e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 13248    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total timesteps  | 13824    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.89e+03 |\n",
      "|    critic_loss      | 7.22e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 13632    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 49       |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total timesteps  | 14208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.85e+03 |\n",
      "|    critic_loss      | 9.14e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 14016    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1840\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total timesteps  | 14592    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.82e+03 |\n",
      "|    critic_loss      | 7.12e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 14400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total timesteps  | 14976    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.8e+03  |\n",
      "|    critic_loss      | 7.55e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 14784    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1850\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total timesteps  | 15360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.76e+03 |\n",
      "|    critic_loss      | 7.16e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 15168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total timesteps  | 15744    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.74e+03 |\n",
      "|    critic_loss      | 6.38e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 15552    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total timesteps  | 16128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.71e+03 |\n",
      "|    critic_loss      | 5.69e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 15936    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1860\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total timesteps  | 16512    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.69e+03 |\n",
      "|    critic_loss      | 6.05e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 16320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total timesteps  | 16896    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.66e+03 |\n",
      "|    critic_loss      | 5.7e+04  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 16704    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1870\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total timesteps  | 17280    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.63e+03 |\n",
      "|    critic_loss      | 5.65e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 17088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total timesteps  | 17664    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.6e+03  |\n",
      "|    critic_loss      | 5.43e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 17472    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total timesteps  | 18048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.58e+03 |\n",
      "|    critic_loss      | 4.34e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 17856    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1880\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 382      |\n",
      "|    total timesteps  | 18432    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.55e+03 |\n",
      "|    critic_loss      | 5.04e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 18240    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 391      |\n",
      "|    total timesteps  | 18816    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.53e+03 |\n",
      "|    critic_loss      | 4.45e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 18624    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1890\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.5e+03  |\n",
      "|    critic_loss      | 4.54e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 19008    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 408      |\n",
      "|    total timesteps  | 19584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.48e+03 |\n",
      "|    critic_loss      | 4.97e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 19392    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total timesteps  | 19968    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.45e+03 |\n",
      "|    critic_loss      | 4.24e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 19776    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1900\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 424      |\n",
      "|    total timesteps  | 20352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.43e+03 |\n",
      "|    critic_loss      | 4.18e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 20160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 433      |\n",
      "|    total timesteps  | 20736    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.41e+03 |\n",
      "|    critic_loss      | 4.12e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 20544    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1910\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 441      |\n",
      "|    total timesteps  | 21120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.39e+03 |\n",
      "|    critic_loss      | 3.9e+04  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 20928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 449      |\n",
      "|    total timesteps  | 21504    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.37e+03 |\n",
      "|    critic_loss      | 4.28e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 21312    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 458      |\n",
      "|    total timesteps  | 21888    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.35e+03 |\n",
      "|    critic_loss      | 3.74e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 21696    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1920\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 466      |\n",
      "|    total timesteps  | 22272    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.33e+03 |\n",
      "|    critic_loss      | 3.72e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 22080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 474      |\n",
      "|    total timesteps  | 22656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.3e+03  |\n",
      "|    critic_loss      | 3.57e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 22464    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1930\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 483      |\n",
      "|    total timesteps  | 23040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.28e+03 |\n",
      "|    critic_loss      | 3.19e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 22848    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 491      |\n",
      "|    total timesteps  | 23424    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.26e+03 |\n",
      "|    critic_loss      | 3.1e+04  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 23232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 499      |\n",
      "|    total timesteps  | 23808    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.24e+03 |\n",
      "|    critic_loss      | 2.97e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 23616    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1940\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 508      |\n",
      "|    total timesteps  | 24192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.21e+03 |\n",
      "|    critic_loss      | 3.24e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 24000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 516      |\n",
      "|    total timesteps  | 24576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.2e+03  |\n",
      "|    critic_loss      | 2.98e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 24384    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1950\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 525      |\n",
      "|    total timesteps  | 24960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.18e+03 |\n",
      "|    critic_loss      | 2.87e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 24768    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 533      |\n",
      "|    total timesteps  | 25344    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.16e+03 |\n",
      "|    critic_loss      | 3.06e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 25152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 542      |\n",
      "|    total timesteps  | 25728    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.14e+03 |\n",
      "|    critic_loss      | 2.66e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 25536    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1960\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 550      |\n",
      "|    total timesteps  | 26112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.12e+03 |\n",
      "|    critic_loss      | 2.55e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 25920    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 559      |\n",
      "|    total timesteps  | 26496    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.1e+03  |\n",
      "|    critic_loss      | 2.62e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 26304    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1970\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 567      |\n",
      "|    total timesteps  | 26880    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.09e+03 |\n",
      "|    critic_loss      | 2.53e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 26688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.08e+03 |\n",
      "|    critic_loss      | 2.42e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 27072    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 584      |\n",
      "|    total timesteps  | 27648    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.06e+03 |\n",
      "|    critic_loss      | 2.2e+04  |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 27456    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1980\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 593      |\n",
      "|    total timesteps  | 28032    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.04e+03 |\n",
      "|    critic_loss      | 2.22e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 27840    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 601      |\n",
      "|    total timesteps  | 28416    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.02e+03 |\n",
      "|    critic_loss      | 2.21e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 28224    |\n",
      "----------------------------------\n",
      "day: 95, episode: 1990\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 610      |\n",
      "|    total timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 1.01e+03 |\n",
      "|    critic_loss      | 2.06e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 28608    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 618      |\n",
      "|    total timesteps  | 29184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 991      |\n",
      "|    critic_loss      | 2.45e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 28992    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 627      |\n",
      "|    total timesteps  | 29568    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 978      |\n",
      "|    critic_loss      | 2.15e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 29376    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2000\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 636      |\n",
      "|    total timesteps  | 29952    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 965      |\n",
      "|    critic_loss      | 1.69e+04 |\n",
      "|    learning_rate    | 0.0003   |\n",
      "|    n_updates        | 29760    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDk2qrlTLZCp"
   },
   "source": [
    "### Model 4: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "el8sK4fo-dl1",
    "outputId": "ed36fa0d-48da-42ad-9cb7-b2696dc544c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 3e-05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.00003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaF80PR0-d_d",
    "outputId": "e4589390-f2aa-47e8-9788-d5fb841f83d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/sac/sac_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 58        |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total timesteps  | 384       |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.43e+03 |\n",
      "|    critic_loss      | 9.96e+04  |\n",
      "|    ent_coef         | 0.101     |\n",
      "|    ent_coef_loss    | 21.5      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 283       |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2030\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 50       |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total timesteps  | 768      |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -2.4e+03 |\n",
      "|    critic_loss      | 9.1e+04  |\n",
      "|    ent_coef         | 0.102    |\n",
      "|    ent_coef_loss    | 21.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 667      |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 48        |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total timesteps  | 1152      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.29e+03 |\n",
      "|    critic_loss      | 3e+03     |\n",
      "|    ent_coef         | 0.103     |\n",
      "|    ent_coef_loss    | 21.1      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 1051      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 46        |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total timesteps  | 1536      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.21e+03 |\n",
      "|    critic_loss      | 1.16e+05  |\n",
      "|    ent_coef         | 0.104     |\n",
      "|    ent_coef_loss    | 21.4      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 1435      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2040\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 46        |\n",
      "|    time_elapsed     | 41        |\n",
      "|    total timesteps  | 1920      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.12e+03 |\n",
      "|    critic_loss      | 1.09e+05  |\n",
      "|    ent_coef         | 0.106     |\n",
      "|    ent_coef_loss    | 21.1      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 1819      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 45        |\n",
      "|    time_elapsed     | 50        |\n",
      "|    total timesteps  | 2304      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -2.04e+03 |\n",
      "|    critic_loss      | 6.63e+04  |\n",
      "|    ent_coef         | 0.107     |\n",
      "|    ent_coef_loss    | 20.9      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 2203      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2050\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 45        |\n",
      "|    time_elapsed     | 59        |\n",
      "|    total timesteps  | 2688      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.91e+03 |\n",
      "|    critic_loss      | 6.01e+04  |\n",
      "|    ent_coef         | 0.108     |\n",
      "|    ent_coef_loss    | 21.1      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 2587      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 68        |\n",
      "|    total timesteps  | 3072      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.91e+03 |\n",
      "|    critic_loss      | 8.44e+04  |\n",
      "|    ent_coef         | 0.109     |\n",
      "|    ent_coef_loss    | 21        |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 2971      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 77        |\n",
      "|    total timesteps  | 3456      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.75e+03 |\n",
      "|    critic_loss      | 5.03e+04  |\n",
      "|    ent_coef         | 0.111     |\n",
      "|    ent_coef_loss    | 21        |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 3355      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2060\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 3840     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -1.7e+03 |\n",
      "|    critic_loss      | 2.36e+04 |\n",
      "|    ent_coef         | 0.112    |\n",
      "|    ent_coef_loss    | 20.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 3739     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 94        |\n",
      "|    total timesteps  | 4224      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.68e+03 |\n",
      "|    critic_loss      | 2.14e+04  |\n",
      "|    ent_coef         | 0.113     |\n",
      "|    ent_coef_loss    | 20.6      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 4123      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2070\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 103       |\n",
      "|    total timesteps  | 4608      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.52e+03 |\n",
      "|    critic_loss      | 5.75e+04  |\n",
      "|    ent_coef         | 0.114     |\n",
      "|    ent_coef_loss    | 20.3      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 4507      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 111       |\n",
      "|    total timesteps  | 4992      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.54e+03 |\n",
      "|    critic_loss      | 3.54e+04  |\n",
      "|    ent_coef         | 0.116     |\n",
      "|    ent_coef_loss    | 20.4      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 4891      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 120       |\n",
      "|    total timesteps  | 5376      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.42e+03 |\n",
      "|    critic_loss      | 1.98e+04  |\n",
      "|    ent_coef         | 0.117     |\n",
      "|    ent_coef_loss    | 20        |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 5275      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2080\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 129       |\n",
      "|    total timesteps  | 5760      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.38e+03 |\n",
      "|    critic_loss      | 3.03e+04  |\n",
      "|    ent_coef         | 0.119     |\n",
      "|    ent_coef_loss    | 20.1      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 5659      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 138       |\n",
      "|    total timesteps  | 6144      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.35e+03 |\n",
      "|    critic_loss      | 6.31e+04  |\n",
      "|    ent_coef         | 0.12      |\n",
      "|    ent_coef_loss    | 20        |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 6043      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2090\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 146       |\n",
      "|    total timesteps  | 6528      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.22e+03 |\n",
      "|    critic_loss      | 2.52e+04  |\n",
      "|    ent_coef         | 0.121     |\n",
      "|    ent_coef_loss    | 20        |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 6427      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 155       |\n",
      "|    total timesteps  | 6912      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.23e+03 |\n",
      "|    critic_loss      | 3.42e+04  |\n",
      "|    ent_coef         | 0.123     |\n",
      "|    ent_coef_loss    | 19.9      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 6811      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 164       |\n",
      "|    total timesteps  | 7296      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.15e+03 |\n",
      "|    critic_loss      | 1.04e+03  |\n",
      "|    ent_coef         | 0.124     |\n",
      "|    ent_coef_loss    | 19.6      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 7195      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 172       |\n",
      "|    total timesteps  | 7680      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.13e+03 |\n",
      "|    critic_loss      | 75.6      |\n",
      "|    ent_coef         | 0.126     |\n",
      "|    ent_coef_loss    | 19.3      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 7579      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1e+05     |\n",
      "|    total_cost       | 0         |\n",
      "|    total_reward     | 0         |\n",
      "|    total_reward_pct | 0         |\n",
      "|    total_trades     | 0         |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 44        |\n",
      "|    time_elapsed     | 181       |\n",
      "|    total timesteps  | 8064      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -1.04e+03 |\n",
      "|    critic_loss      | 462       |\n",
      "|    ent_coef         | 0.127     |\n",
      "|    ent_coef_loss    | 19.4      |\n",
      "|    learning_rate    | 3e-05     |\n",
      "|    n_updates        | 7963      |\n",
      "-----------------------------------\n",
      "day: 95, episode: 2110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total timesteps  | 8448     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -979     |\n",
      "|    critic_loss      | 8.71e+03 |\n",
      "|    ent_coef         | 0.128    |\n",
      "|    ent_coef_loss    | 19.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 8347     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total timesteps  | 8832     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -965     |\n",
      "|    critic_loss      | 1.65e+04 |\n",
      "|    ent_coef         | 0.13     |\n",
      "|    ent_coef_loss    | 19       |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 8731     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total timesteps  | 9216     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -898     |\n",
      "|    critic_loss      | 1.34e+04 |\n",
      "|    ent_coef         | 0.131    |\n",
      "|    ent_coef_loss    | 19.1     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 9115     |\n",
      "----------------------------------\n",
      "day: 95, episode: 2120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -916     |\n",
      "|    critic_loss      | 558      |\n",
      "|    ent_coef         | 0.133    |\n",
      "|    ent_coef_loss    | 18.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 9499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total timesteps  | 9984     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -823     |\n",
      "|    critic_loss      | 1.09e+04 |\n",
      "|    ent_coef         | 0.135    |\n",
      "|    ent_coef_loss    | 18.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 9883     |\n",
      "----------------------------------\n",
      "day: 95, episode: 2130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total timesteps  | 10368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -789     |\n",
      "|    critic_loss      | 1.44e+04 |\n",
      "|    ent_coef         | 0.136    |\n",
      "|    ent_coef_loss    | 18.7     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 10267    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 10752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -784     |\n",
      "|    critic_loss      | 960      |\n",
      "|    ent_coef         | 0.138    |\n",
      "|    ent_coef_loss    | 18.7     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 10651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total timesteps  | 11136    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -706     |\n",
      "|    critic_loss      | 5.32e+03 |\n",
      "|    ent_coef         | 0.139    |\n",
      "|    ent_coef_loss    | 18.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 11035    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total timesteps  | 11520    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -703     |\n",
      "|    critic_loss      | 330      |\n",
      "|    ent_coef         | 0.141    |\n",
      "|    ent_coef_loss    | 18.3     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 11419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total timesteps  | 11904    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -679     |\n",
      "|    critic_loss      | 3.88e+03 |\n",
      "|    ent_coef         | 0.143    |\n",
      "|    ent_coef_loss    | 18.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 11803    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total timesteps  | 12288    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -633     |\n",
      "|    critic_loss      | 754      |\n",
      "|    ent_coef         | 0.144    |\n",
      "|    ent_coef_loss    | 18.3     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 12187    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 12672    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -589     |\n",
      "|    critic_loss      | 6.05e+03 |\n",
      "|    ent_coef         | 0.146    |\n",
      "|    ent_coef_loss    | 18.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 12571    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total timesteps  | 13056    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -550     |\n",
      "|    critic_loss      | 1.25e+04 |\n",
      "|    ent_coef         | 0.148    |\n",
      "|    ent_coef_loss    | 18       |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 12955    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total timesteps  | 13440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -563     |\n",
      "|    critic_loss      | 539      |\n",
      "|    ent_coef         | 0.149    |\n",
      "|    ent_coef_loss    | 17.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 13339    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total timesteps  | 13824    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -550     |\n",
      "|    critic_loss      | 3.3e+03  |\n",
      "|    ent_coef         | 0.151    |\n",
      "|    ent_coef_loss    | 17.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 13723    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total timesteps  | 14208    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -504     |\n",
      "|    critic_loss      | 2.79e+03 |\n",
      "|    ent_coef         | 0.153    |\n",
      "|    ent_coef_loss    | 17.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 14107    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total timesteps  | 14592    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -479     |\n",
      "|    critic_loss      | 2.17e+03 |\n",
      "|    ent_coef         | 0.154    |\n",
      "|    ent_coef_loss    | 17.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 14491    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total timesteps  | 14976    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -458     |\n",
      "|    critic_loss      | 1.84e+03 |\n",
      "|    ent_coef         | 0.156    |\n",
      "|    ent_coef_loss    | 17.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 14875    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total timesteps  | 15360    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -408     |\n",
      "|    critic_loss      | 2.19e+03 |\n",
      "|    ent_coef         | 0.158    |\n",
      "|    ent_coef_loss    | 17.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 15259    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total timesteps  | 15744    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -399     |\n",
      "|    critic_loss      | 851      |\n",
      "|    ent_coef         | 0.16     |\n",
      "|    ent_coef_loss    | 17.1     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 15643    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total timesteps  | 16128    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -405     |\n",
      "|    critic_loss      | 1.44e+03 |\n",
      "|    ent_coef         | 0.162    |\n",
      "|    ent_coef_loss    | 17       |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 16027    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total timesteps  | 16512    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -372     |\n",
      "|    critic_loss      | 1.14e+03 |\n",
      "|    ent_coef         | 0.164    |\n",
      "|    ent_coef_loss    | 16.8     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 16411    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 383      |\n",
      "|    total timesteps  | 16896    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -367     |\n",
      "|    critic_loss      | 418      |\n",
      "|    ent_coef         | 0.166    |\n",
      "|    ent_coef_loss    | 16.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 16795    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 392      |\n",
      "|    total timesteps  | 17280    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -353     |\n",
      "|    critic_loss      | 450      |\n",
      "|    ent_coef         | 0.167    |\n",
      "|    ent_coef_loss    | 16.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 17179    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 400      |\n",
      "|    total timesteps  | 17664    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -315     |\n",
      "|    critic_loss      | 970      |\n",
      "|    ent_coef         | 0.169    |\n",
      "|    ent_coef_loss    | 16.8     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 17563    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 409      |\n",
      "|    total timesteps  | 18048    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -313     |\n",
      "|    critic_loss      | 1.1e+03  |\n",
      "|    ent_coef         | 0.171    |\n",
      "|    ent_coef_loss    | 16.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 17947    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 418      |\n",
      "|    total timesteps  | 18432    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -301     |\n",
      "|    critic_loss      | 440      |\n",
      "|    ent_coef         | 0.173    |\n",
      "|    ent_coef_loss    | 16.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 18331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 426      |\n",
      "|    total timesteps  | 18816    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -283     |\n",
      "|    critic_loss      | 590      |\n",
      "|    ent_coef         | 0.175    |\n",
      "|    ent_coef_loss    | 16.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 18715    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 435      |\n",
      "|    total timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -262     |\n",
      "|    critic_loss      | 673      |\n",
      "|    ent_coef         | 0.177    |\n",
      "|    ent_coef_loss    | 16.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 19099    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 444      |\n",
      "|    total timesteps  | 19584    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -244     |\n",
      "|    critic_loss      | 832      |\n",
      "|    ent_coef         | 0.179    |\n",
      "|    ent_coef_loss    | 16.1     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 19483    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 452      |\n",
      "|    total timesteps  | 19968    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -242     |\n",
      "|    critic_loss      | 577      |\n",
      "|    ent_coef         | 0.182    |\n",
      "|    ent_coef_loss    | 16       |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 19867    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 461      |\n",
      "|    total timesteps  | 20352    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -239     |\n",
      "|    critic_loss      | 1.19e+03 |\n",
      "|    ent_coef         | 0.184    |\n",
      "|    ent_coef_loss    | 15.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 20251    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 470      |\n",
      "|    total timesteps  | 20736    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -201     |\n",
      "|    critic_loss      | 613      |\n",
      "|    ent_coef         | 0.186    |\n",
      "|    ent_coef_loss    | 15.8     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 20635    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 479      |\n",
      "|    total timesteps  | 21120    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -211     |\n",
      "|    critic_loss      | 945      |\n",
      "|    ent_coef         | 0.188    |\n",
      "|    ent_coef_loss    | 15.8     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 21019    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 488      |\n",
      "|    total timesteps  | 21504    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -149     |\n",
      "|    critic_loss      | 1.09e+03 |\n",
      "|    ent_coef         | 0.19     |\n",
      "|    ent_coef_loss    | 15.7     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 21403    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 496      |\n",
      "|    total timesteps  | 21888    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -167     |\n",
      "|    critic_loss      | 347      |\n",
      "|    ent_coef         | 0.192    |\n",
      "|    ent_coef_loss    | 15.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 21787    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 505      |\n",
      "|    total timesteps  | 22272    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -160     |\n",
      "|    critic_loss      | 430      |\n",
      "|    ent_coef         | 0.195    |\n",
      "|    ent_coef_loss    | 15.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 22171    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 514      |\n",
      "|    total timesteps  | 22656    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -132     |\n",
      "|    critic_loss      | 226      |\n",
      "|    ent_coef         | 0.197    |\n",
      "|    ent_coef_loss    | 15.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 22555    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 523      |\n",
      "|    total timesteps  | 23040    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -136     |\n",
      "|    critic_loss      | 121      |\n",
      "|    ent_coef         | 0.199    |\n",
      "|    ent_coef_loss    | 15.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 22939    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 531      |\n",
      "|    total timesteps  | 23424    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -128     |\n",
      "|    critic_loss      | 68.2     |\n",
      "|    ent_coef         | 0.201    |\n",
      "|    ent_coef_loss    | 15.1     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 23323    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 540      |\n",
      "|    total timesteps  | 23808    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -129     |\n",
      "|    critic_loss      | 209      |\n",
      "|    ent_coef         | 0.204    |\n",
      "|    ent_coef_loss    | 15.3     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 23707    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 549      |\n",
      "|    total timesteps  | 24192    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -109     |\n",
      "|    critic_loss      | 311      |\n",
      "|    ent_coef         | 0.206    |\n",
      "|    ent_coef_loss    | 14.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 24091    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 558      |\n",
      "|    total timesteps  | 24576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -106     |\n",
      "|    critic_loss      | 478      |\n",
      "|    ent_coef         | 0.208    |\n",
      "|    ent_coef_loss    | 14.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 24475    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 566      |\n",
      "|    total timesteps  | 24960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -83.5    |\n",
      "|    critic_loss      | 390      |\n",
      "|    ent_coef         | 0.211    |\n",
      "|    ent_coef_loss    | 14.7     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 24859    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 575      |\n",
      "|    total timesteps  | 25344    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -73.5    |\n",
      "|    critic_loss      | 196      |\n",
      "|    ent_coef         | 0.213    |\n",
      "|    ent_coef_loss    | 14.3     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 25243    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 584      |\n",
      "|    total timesteps  | 25728    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -73.4    |\n",
      "|    critic_loss      | 62.8     |\n",
      "|    ent_coef         | 0.216    |\n",
      "|    ent_coef_loss    | 14.5     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 25627    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 593      |\n",
      "|    total timesteps  | 26112    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -67.3    |\n",
      "|    critic_loss      | 239      |\n",
      "|    ent_coef         | 0.218    |\n",
      "|    ent_coef_loss    | 14.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 26011    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 601      |\n",
      "|    total timesteps  | 26496    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -67.8    |\n",
      "|    critic_loss      | 214      |\n",
      "|    ent_coef         | 0.221    |\n",
      "|    ent_coef_loss    | 14.1     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 26395    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 610      |\n",
      "|    total timesteps  | 26880    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -47.7    |\n",
      "|    critic_loss      | 151      |\n",
      "|    ent_coef         | 0.223    |\n",
      "|    ent_coef_loss    | 14.3     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 26779    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 619      |\n",
      "|    total timesteps  | 27264    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -60.7    |\n",
      "|    critic_loss      | 351      |\n",
      "|    ent_coef         | 0.226    |\n",
      "|    ent_coef_loss    | 13.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 27163    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 628      |\n",
      "|    total timesteps  | 27648    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -39.6    |\n",
      "|    critic_loss      | 134      |\n",
      "|    ent_coef         | 0.229    |\n",
      "|    ent_coef_loss    | 13.9     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 27547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 636      |\n",
      "|    total timesteps  | 28032    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -43.1    |\n",
      "|    critic_loss      | 126      |\n",
      "|    ent_coef         | 0.231    |\n",
      "|    ent_coef_loss    | 13.6     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 27931    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 645      |\n",
      "|    total timesteps  | 28416    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -27.6    |\n",
      "|    critic_loss      | 249      |\n",
      "|    ent_coef         | 0.234    |\n",
      "|    ent_coef_loss    | 13.8     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 28315    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 654      |\n",
      "|    total timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -30.2    |\n",
      "|    critic_loss      | 256      |\n",
      "|    ent_coef         | 0.237    |\n",
      "|    ent_coef_loss    | 13.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 28699    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 663      |\n",
      "|    total timesteps  | 29184    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -12.2    |\n",
      "|    critic_loss      | 41.2     |\n",
      "|    ent_coef         | 0.239    |\n",
      "|    ent_coef_loss    | 13.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 29083    |\n",
      "----------------------------------\n",
      "day: 95, episode: 2330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 671      |\n",
      "|    total timesteps  | 29568    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -22.8    |\n",
      "|    critic_loss      | 114      |\n",
      "|    ent_coef         | 0.242    |\n",
      "|    ent_coef_loss    | 13.4     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 29467    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1e+05    |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 0        |\n",
      "|    total_reward_pct | 0        |\n",
      "|    total_trades     | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total timesteps  | 29952    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -3.6     |\n",
      "|    critic_loss      | 24.4     |\n",
      "|    ent_coef         | 0.245    |\n",
      "|    ent_coef_loss    | 13.2     |\n",
      "|    learning_rate    | 3e-05    |\n",
      "|    n_updates        | 29851    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KE1Xm9N9TnTn"
   },
   "source": [
    "### Trading\n",
    "* we use the environment class we initialized at 5.3 to create a stock trading environment\n",
    "* Assume that we have $100,000 initial capital at 2019-01-01. \n",
    "* We use the trained model of PPO to trade AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "kLFUwxhCoHN_",
    "outputId": "a1d972e2-0350-4b00-8ad7-4d6a0191a959"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>kdjk</th>\n",
       "      <th>open_2_sma</th>\n",
       "      <th>boll</th>\n",
       "      <th>close_10.0_le_5_c</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>dma</th>\n",
       "      <th>trix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31 13:45:00+00:00</td>\n",
       "      <td>1.14928</td>\n",
       "      <td>1.14954</td>\n",
       "      <td>1.14844</td>\n",
       "      <td>1.14947</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>43.262469</td>\n",
       "      <td>62.274537</td>\n",
       "      <td>13.486620</td>\n",
       "      <td>88.463576</td>\n",
       "      <td>1.146920</td>\n",
       "      <td>1.139214</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.412250</td>\n",
       "      <td>-0.006648</td>\n",
       "      <td>-0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31 14:00:00+00:00</td>\n",
       "      <td>1.14947</td>\n",
       "      <td>1.14956</td>\n",
       "      <td>1.14825</td>\n",
       "      <td>1.14872</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>42.699453</td>\n",
       "      <td>64.736611</td>\n",
       "      <td>12.640914</td>\n",
       "      <td>87.547146</td>\n",
       "      <td>1.149375</td>\n",
       "      <td>1.140041</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>-0.004729</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31 14:15:00+00:00</td>\n",
       "      <td>1.14872</td>\n",
       "      <td>1.14934</td>\n",
       "      <td>1.14865</td>\n",
       "      <td>1.14885</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>42.832855</td>\n",
       "      <td>70.894950</td>\n",
       "      <td>12.640914</td>\n",
       "      <td>87.673154</td>\n",
       "      <td>1.149095</td>\n",
       "      <td>1.140899</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.074830</td>\n",
       "      <td>-0.003978</td>\n",
       "      <td>0.006982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-31 14:30:00+00:00</td>\n",
       "      <td>1.14886</td>\n",
       "      <td>1.14914</td>\n",
       "      <td>1.14853</td>\n",
       "      <td>1.14870</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>42.714156</td>\n",
       "      <td>75.645950</td>\n",
       "      <td>12.038360</td>\n",
       "      <td>86.906819</td>\n",
       "      <td>1.148790</td>\n",
       "      <td>1.141765</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.625850</td>\n",
       "      <td>-0.003245</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-31 14:45:00+00:00</td>\n",
       "      <td>1.14869</td>\n",
       "      <td>1.14882</td>\n",
       "      <td>1.14773</td>\n",
       "      <td>1.14776</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>41.960338</td>\n",
       "      <td>76.566181</td>\n",
       "      <td>7.924108</td>\n",
       "      <td>81.067131</td>\n",
       "      <td>1.148775</td>\n",
       "      <td>1.142367</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.612245</td>\n",
       "      <td>-0.002643</td>\n",
       "      <td>0.017503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date     open     high  ...      wr_10       dma      trix\n",
       "0 2019-01-31 13:45:00+00:00  1.14928  1.14954  ...   0.412250 -0.006648 -0.007552\n",
       "1 2019-01-31 14:00:00+00:00  1.14947  1.14956  ...  14.285714 -0.004729  0.000094\n",
       "2 2019-01-31 14:15:00+00:00  1.14872  1.14934  ...  12.074830 -0.003978  0.006982\n",
       "3 2019-01-31 14:30:00+00:00  1.14886  1.14914  ...  14.625850 -0.003245  0.012900\n",
       "4 2019-01-31 14:45:00+00:00  1.14869  1.14882  ...  30.612245 -0.002643  0.017503\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLHl6V7eqV6_"
   },
   "outputs": [],
   "source": [
    "## make a prediction and get the account value change\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                                           test_data = trade,\n",
    "                                           test_env = env_trade,\n",
    "                                           test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYXxFzD5TnTw"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Performance\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GwqOO-v1NVz"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "C9cpPm9YYxHC",
    "outputId": "20e35b8b-ea89-4631-9583-3ce40d15db93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-24958daad3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackTestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mBackTestStats\u001b[0;34m(account_value)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mBackTestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccount_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mDRL_strat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_strat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mperf_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mget_daily_return\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# df=df.dropna()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0msharpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m252\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mannual_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m252\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-Tenjb0hcNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4Gw3HNr1TDU"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MA_8LuZE1J3X"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to AAPL itself buy-and-hold===========\")\n",
    "%matplotlib inline\n",
    "BackTestPlot(account_value=df_account_value, \n",
    "             baseline_ticker = 'AAPL',\n",
    "             baseline_start = '2019-01-01',\n",
    "             baseline_end = '2021-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSFMdgCJE4O-"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpR7aQIwqdC4"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSFRXQfYFTQf"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('^GSPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunrA4mjE9la"
   },
   "source": [
    "<a id='6.4'></a>\n",
    "## 7.4 Compare to Stock Market Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5Ca2gHxi1gzX",
    "outputId": "01b2e742-e164-46f0-b280-296a849818ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to S&P 500===========\n",
      "annual return:  -0.02065151445176383\n",
      "sharpe ratio:  -1.6896134032497638\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (483, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-01-03</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-05-20</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>4</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>-0.021%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>-0.008%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>0.012%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>-1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-0.008%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>-2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>38.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-0.002%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to S&P 500===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "BackTestPlot(df_account_value, baseline_ticker = '^GSPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3_aHGEOTCluG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinRL_single_stock_trading v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('rl_fx': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3d949faa22e4c1a1e3c7af243aab665cfbba58d9d0edeb49ef5b9ad103ff1380"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}